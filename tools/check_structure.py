#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
3AIå·¥ä½œå®¤ç›®å½•ç»“æ„æ£€æŸ¥å·¥å…·

åŠŸèƒ½ï¼š
1. æ£€æŸ¥é¡¹ç›®ç›®å½•ç»“æ„æ˜¯å¦ç¬¦åˆæ ‡å‡†
2. éªŒè¯å¿…å¤‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
3. æ£€æŸ¥æ–‡ä»¶å‘½åè§„èŒƒ
4. è¯†åˆ«ç¦æ­¢çš„ç›®å½•å’Œæ–‡ä»¶
5. ç”Ÿæˆè¯¦ç»†çš„æ£€æŸ¥æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    python tools/structure_check.py
    python tools/structure_check.py --verbose  # è¯¦ç»†è¾“å‡º
    python tools/structure_check.py --output logs/  # æŒ‡å®šè¾“å‡ºç›®å½•

ä½œè€…ï¼šé›¨ä¿Š
ç‰ˆæœ¬ï¼š2.0
æ›´æ–°ï¼š2025-06-13
"""

from pathlib import Path
import os
import re
from datetime import datetime
import json
from typing import Union, List, Set, Dict, Optional
import sys
import fnmatch

# å¯¼å…¥é…ç½®åŠ è½½å™¨
from config_loader import get_config

# åŠ è½½é…ç½®
CONFIG = get_config()
PROJECT_ROOT = CONFIG['project_root']


def parse_structure_standard() -> Dict:
    """ä»ç›®å½•ç»“æ„æ ‡å‡†æ¸…å•æ–‡ä»¶ä¸­è§£ææ£€æŸ¥æ ‡å‡†"""
    # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æ ‡å‡†æ¸…å•æ–‡ä»¶è·¯å¾„
    standard_list_file = CONFIG.get(
        'structure_check',
        {}).get(
        'standard_list_file',
        'docs/01-è®¾è®¡/ç›®å½•ç»“æ„æ ‡å‡†æ¸…å•.md')
    md_file_path = PROJECT_ROOT / standard_list_file
    print(f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶åŠ è½½æ ‡å‡†æ¸…å•æ–‡ä»¶è·¯å¾„: {md_file_path}")
    if not md_file_path.exists():
        print(f"âš ï¸ æ ‡å‡†æ–‡ä»¶ä¸å­˜åœ¨: {md_file_path}")
        return get_fallback_structure()

    try:
        with open(md_file_path, "r", encoding="utf-8") as f:
            content = f.read()

        # è§£æMarkdownæ–‡ä»¶å†…å®¹ä»¥æå–æ£€æŸ¥æ ‡å‡†
        parsed_structure = {
            "required_dirs": [],
            "required_files": {},
            "template_files": {},
            "forbidden_patterns": [],
            "naming_rules": {
                "docs": r"^[\u4e00-\u9fa5a-zA-Z0-9\-_\s]+\.(md|txt)$",
                "tools": r"^[a-zA-Z0-9\-_]+\.(py|js|sh|bat|ps1)$",
                "config": r"^[a-zA-Z0-9\-_]+\.(json|yaml|yml|ini|conf)$",
            }
        }

        # è§£æå¿…éœ€ç›®å½•
        required_dirs_match = re.search(
            r"### 1\.1 æ ¸å¿ƒç›®å½•\s*```\s*([^`]+)```", content, re.DOTALL)
        if required_dirs_match:
            dirs_text = required_dirs_match.group(1).strip()
            parsed_structure["required_dirs"] = [d.strip() for d in dirs_text.split(
                '\n') if d.strip() and not d.strip().startswith('#')]

        # è§£æé¡¹ç›®æ–‡ä»¶æ¸…å• (æ›¿ä»£æ—§çš„ required_files å’Œ template_files)
        project_files_match = re.search(
            r"## 2\. é¡¹ç›®æ–‡ä»¶æ¸…å•\s*```markdown\s*([^`]+)```", content, re.DOTALL)
        if project_files_match:
            files_text = project_files_match.group(1).strip()
            current_dir = ""  # ç”¨äºè®°å½•å½“å‰çš„ç›®å½•ä¸Šä¸‹æ–‡
            # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… '### 2.ç›®å½•è·¯å¾„' æˆ– '### 2.ç›®å½•è·¯å¾„/'
            dir_pattern = re.compile(
                r"^###\s*\d+(\.\d+)*\s*([^\s(]+?)/?$")  # åŒ¹é…ç›®å½•è¡Œ
            # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… '- `æ–‡ä»¶è·¯å¾„` (æè¿°)'
            file_item_pattern = re.compile(
                r"^-\s*`([^`]+)`\s*\(([^)]+)\)$")  # åŒ¹é…æ–‡ä»¶è¡Œ

            for line in files_text.split('\n'):
                line = line.strip()
                if not line or line.startswith('#'):
                    continue

                dir_match = dir_pattern.match(line)
                if dir_match:
                    # current_dir = dir_match.group(2).strip() # è·å–æ•è·ç»„2ä½œä¸ºç›®å½•è·¯å¾„
                    # ä¿®æ­£ï¼šç›®å½•è¡Œæœ¬èº«ä¸ç›´æ¥ç”¨äºæ‹¼æ¥ï¼Œè€Œæ˜¯ä½œä¸ºæ–‡ä»¶è¡Œè·¯å¾„çš„å‰ç¼€å‚è€ƒ
                    # ä» '### 2.bak/.git' æˆ– '### 2.bak/.git/' ä¸­æå– 'bak/.git'
                    raw_dir_path = dir_match.group(2).strip()
                    if raw_dir_path.endswith('/'):
                        current_dir = raw_dir_path[:-1]
                    else:
                        current_dir = raw_dir_path
                    continue  # å¤„ç†å®Œç›®å½•è¡Œåï¼Œç»§ç»­ä¸‹ä¸€è¡Œ

                file_match = file_item_pattern.match(line)
                if file_match:  # ä¸å†ä¸¥æ ¼è¦æ±‚ current_dirï¼Œå› ä¸ºæ–‡ä»¶è·¯å¾„æœ¬èº«æ˜¯å®Œæ•´çš„
                    # æå–æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ 'bak/.git/HEAD'
                    file_path = file_match.group(1).strip()
                    description = file_match.group(2).strip()  # æå–æè¿°

                    # ç§»é™¤è·¯å¾„å¼€å¤´çš„ './' æˆ– '.\'
                    if file_path.startswith('./'):
                        file_path = file_path[2:]
                    elif file_path.startswith('.\\'):  # Windowsè·¯å¾„
                        file_path = file_path[2:]

                    parsed_structure["required_files"][file_path] = description

        # è§£æç¦æ­¢åˆ›å»ºçš„ç›®å½•/æ–‡ä»¶
        forbidden_patterns_match = re.search(
            r"### 3\.1 ç¦æ­¢åˆ›å»ºçš„ç›®å½•/æ–‡ä»¶ç±»å‹\s*```\s*([^`]+)```", content, re.DOTALL)
        if forbidden_patterns_match:
            patterns_text = forbidden_patterns_match.group(1).strip()
            parsed_structure["forbidden_patterns"] = [p.strip() for p in patterns_text.split(
                '\n') if p.strip() and not p.strip().startswith('#')]

        # è§£ææ–‡ä»¶å‘½åè§„èŒƒ (å¦‚æœæ ‡å‡†æ–‡æ¡£ä¸­æœ‰å®šä¹‰ï¼Œåˆ™è¦†ç›–é»˜è®¤å€¼)
        docs_naming_match = re.search(
            r"### 4\.1 æ–‡æ¡£æ–‡ä»¶\s*.*?æ ¼å¼ï¼š`([^`]+)`", content, re.DOTALL)
        if docs_naming_match:
            # ä» "æ ¼å¼ï¼š`åŠŸèƒ½æè¿°.md`" ä¸­æå– `åŠŸèƒ½æè¿°.md` è¿™éƒ¨åˆ†ä½œä¸ºè§„åˆ™çš„åŸºç¡€
            # æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ›´é€šç”¨çš„æ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…æ–‡ä»¶åï¼Œè€Œä¸æ˜¯æè¿°æ€§æ–‡æœ¬
            # å‡è®¾æ ‡å‡†æ–‡æ¡£ä¸­çš„ç¤ºä¾‹ä»£è¡¨äº†å…è®¸çš„æ¨¡å¼ï¼Œä¾‹å¦‚ .md
            # è¿™é‡Œæˆ‘ä»¬ç®€åŒ–å¤„ç†ï¼Œå¦‚æœæ‰¾åˆ°åŒ¹é…å°±ç”¨ä¸€ä¸ªè¾ƒå®½æ¾çš„è§„åˆ™ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´ç²¾ç¡®çš„è§„åˆ™æå–
            # æˆ–è€…ï¼Œæ ‡å‡†æ–‡æ¡£ç›´æ¥æä¾›æ­£åˆ™è¡¨è¾¾å¼
            # åŸºäºç¤ºä¾‹ `åŠŸèƒ½æè¿°.md`ï¼Œæˆ‘ä»¬å…è®¸ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ç©ºæ ¼ã€ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦ï¼Œä¸”ä»¥ .md ç»“å°¾
            # å¯¹äº docs ç›®å½•ä¸‹çš„ .json å’Œ .env æ–‡ä»¶ï¼Œæˆ‘ä»¬éœ€è¦æ›´çµæ´»çš„è§„åˆ™
            # æš‚æ—¶ä½¿ç”¨ä¸€ä¸ªæ¯”è¾ƒé€šç”¨çš„è§„åˆ™ï¼Œå…è®¸å­—æ¯æ•°å­—å’Œä¸€äº›ç‰¹æ®Šå­—ç¬¦ï¼Œä»¥åŠå¸¸è§çš„æ–‡æ¡£å’Œé…ç½®æ–‡ä»¶æ‰©å±•å
            # å°† + ä¿®æ”¹ä¸º * ä»¥å…è®¸ç©ºçš„æ–‡ä»¶åä¸»ä½“ (ä¾‹å¦‚ .env)
            parsed_structure["naming_rules"][
                "docs"] = r"^[\u4e00-\u9fa5a-zA-Z0-9\-_\s\.]*\.(md|txt|json|env|example)$"

        tools_naming_match = re.search(
            r"### 4\.2 ä»£ç æ–‡ä»¶\s*.*?æ ¼å¼ï¼š`([^`]+)`", content, re.DOTALL)
        if tools_naming_match:
            # ç¤ºä¾‹ï¼š`module_name.py`
            parsed_structure["naming_rules"][
                "tools"] = r"^[a-zA-Z0-9_\-]+\.(py|js|sh|bat|ps1)$"

        config_naming_match = re.search(
            r"### 4\.3 é…ç½®æ–‡ä»¶\s*.*?æ ¼å¼ï¼š`([^`]+)`", content, re.DOTALL)
        if config_naming_match:
            # ç¤ºä¾‹ï¼š`config.json`
            parsed_structure["naming_rules"][
                "config"] = r"^[a-zA-Z0-9\._\-]+\.(json|yaml|yml|ini|conf|js|cfg|rc)$"

        print("ğŸ“‹ å·²ä»ç›®å½•ç»“æ„æ ‡å‡†æ¸…å•.mdåŠ¨æ€è§£ææ£€æŸ¥æ ‡å‡†")
        return parsed_structure

    except Exception as e:
        print(f"âŒ è§£ææ ‡å‡†æ–‡ä»¶å¤±è´¥: {e}")
        return get_fallback_structure()


def get_fallback_structure() -> Dict:
    """è·å–å¤‡ç”¨çš„ç¡¬ç¼–ç ç»“æ„æ ‡å‡†ï¼ˆæ›´æ–°ä¸ºæ–°çš„æ ‡å‡†åŒ–ç»“æ„ï¼‰"""
    return {
        "required_dirs": [
            # GitHubä»“åº“ç»“æ„è§„èŒƒçš„ä¸‰ä¸ªä¸»è¦æ–‡ä»¶å¤¹
            "docs",
            "project",
            "tools",
            # æœ¬åœ°é¡¹ç›®ç»“æ„
            "docs/01-è®¾è®¡",
            "docs/02-å¼€å‘",
            "docs/03-ç®¡ç†",
            "docs/04-æ¥å£",
            "docs/05-ç”¨æˆ·",
            "docs/04-æ¨¡æ¿",
            "logs",
            "bak",
        ],
        "optional_dirs": [".devcontainer", ".github", ".vscode", "config", "scripts"],
        "required_files": {
            "docs/01-é¡¹ç›®è§„åˆ’/é¡¹ç›®ç›®æ ‡å®šä¹‰.md": "é¡¹ç›®æ ¸å¿ƒç›®æ ‡å®šä¹‰",
            "docs/01-é¡¹ç›®è§„åˆ’/éœ€æ±‚åˆ†æ.md": "éœ€æ±‚åˆ†ææ–‡æ¡£",
            "docs/01-é¡¹ç›®è§„åˆ’/ä¸“ä¸šé¡¹ç›®å¼€å‘æ¡†æ¶åˆ†ææŠ¥å‘Š.md": "ä¸“ä¸šæ¡†æ¶åˆ†æ",
            "docs/01-é¡¹ç›®è§„åˆ’/é¡¹ç›®å®æ–½è¡ŒåŠ¨è®¡åˆ’.md": "å®æ–½è¡ŒåŠ¨è®¡åˆ’",
            "docs/02-æŠ€æœ¯è®¾è®¡/ç³»ç»Ÿæ¶æ„è®¾è®¡.md": "ç³»ç»Ÿæ¶æ„è®¾è®¡",
            "docs/03-å¼€å‘æŒ‡å—/å¼€å‘ç¯å¢ƒæ­å»º.md": "å¼€å‘ç¯å¢ƒé…ç½®æŒ‡å—ï¼ˆåˆå¹¶ç‰ˆï¼‰",
            "docs/04-APIæ–‡æ¡£/APIè®¾è®¡è§„èŒƒ.md": "APIè®¾è®¡è§„èŒƒ",
            "docs/06-é¡¹ç›®ç®¡ç†/å·¥ä½œå®Œæˆæ£€æŸ¥æ¸…å•.md": "å·¥ä½œæ£€æŸ¥æ¸…å•",
            "docs/06-é¡¹ç›®ç®¡ç†/é—®é¢˜è§£å†³è®°å½•.md": "é—®é¢˜è®°å½•",
            "docs/06-é¡¹ç›®ç®¡ç†/å¼€å‘æ—¥å¿—.md": "å¼€å‘æ—¥å¿—",
        },
        "template_files": {
            "docs/07-æ¨¡æ¿æ–‡ä»¶/ä»»åŠ¡ä¹¦æ ‡å‡†æ¨¡æ¿.md": "ä»»åŠ¡ä¹¦æ¨¡æ¿",
            "docs/07-æ¨¡æ¿æ–‡ä»¶/æ£€æŸ¥æ¸…å•æ ‡å‡†æ¨¡æ¿.md": "æ£€æŸ¥æ¸…å•æ¨¡æ¿",
            "docs/07-æ¨¡æ¿æ–‡ä»¶/é—®é¢˜è®°å½•æ ‡å‡†æ¨¡æ¿.md": "é—®é¢˜è®°å½•æ¨¡æ¿",
        },
        "forbidden_patterns": [
            r".*[Tt]emp.*",
            r".*[Tt]mp.*",
            r".*[Bb]ackup.*",
            r".*[Oo]ld.*",
            r".*[Cc]ache.*",
            r".*\.log$",
            r".*\.tmp$",
            r".*~$",
        ],
        "naming_rules": {
            "docs": r"^[\u4e00-\u9fa5a-zA-Z0-9\-_\s]+\.(md|txt)$",
            "tools": r"^[a-zA-Z0-9\-_]+\.(py|js|sh|bat|ps1)$",
            "config": r"^[a-zA-Z0-9\-_]+\.(json|yaml|yml|ini|conf)$",
        },
    }


class StructureChecker:
    """ç›®å½•ç»“æ„æ£€æŸ¥å™¨"""

    def __init__(self, project_root: Union[str, Path] = PROJECT_ROOT):
        self.project_root = Path(project_root).resolve()
        self.standard_structure = parse_structure_standard()  # ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„
        self.issues: List[str] = []
        self.warnings: List[str] = []
        self.info: List[str] = []
        self.missing_items: List[str] = []  # é¢„æœŸä½†å®é™…ä¸å­˜åœ¨çš„
        self.redundant_items: Set[str] = set()  # å®é™…å­˜åœ¨ä½†ä¸åœ¨é¢„æœŸä¸­çš„ï¼Œæ”¹ä¸ºsetå»é‡

        # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æ’é™¤ç›®å½•
        self.excluded_dirs_for_redundancy_check: Set[str] = set(
            CONFIG.get(
                'structure_check', {}).get(
                'excluded_dirs_for_redundancy', [
                    'bak', 'logs']))
        self.info.append(
            f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶åŠ è½½æ’é™¤ç›®å½•: {
                ', '.join(
                    self.excluded_dirs_for_redundancy_check)}")

        # è·å–ç™½åå•è·¯å¾„æ—¶è½¬æ¢ä¸ºå°å†™
        raw_required_dirs = self.standard_structure.get("required_dirs", [])
        raw_required_files_map = self.standard_structure.get(
            "required_files", {})

        self.whitelist_dirs_str_lower = set(
            d.lower() for d in raw_required_dirs)
        # å¯¹äº required_filesï¼Œé”®ï¼ˆè·¯å¾„ï¼‰è½¬å°å†™ï¼Œå€¼ï¼ˆæè¿°ï¼‰ä¿æŒä¸å˜
        self.required_files_map_lower_keys = {
            k.lower(): v for k, v in raw_required_files_map.items()}
        self.whitelist_files_str_lower = set(
            self.required_files_map_lower_keys.keys())

        # å°†å°å†™ç›¸å¯¹è·¯å¾„å­—ç¬¦ä¸²è½¬æ¢ä¸º Path å¯¹è±¡ï¼Œä»¥ä¾¿äºæ¯”è¾ƒ
        self.whitelist_dirs_pathobj = {
            Path(p) for p in self.whitelist_dirs_str_lower}
        self.whitelist_files_pathobj = {
            Path(p) for p in self.whitelist_files_str_lower}

        if self.standard_structure.get("required_dirs"):  # æ£€æŸ¥æ˜¯å¦æˆåŠŸè§£æ
            print("âœ… ç›®å½•ç»“æ„æ ‡å‡†æ¸…å•è§£ææˆåŠŸã€‚")
            self.info.append("ğŸ“‹ å·²ä»ç›®å½•ç»“æ„æ ‡å‡†æ¸…å•.mdåŠ è½½æ£€æŸ¥æ ‡å‡†")
        else:
            self.issues.append(
                "âŒ é”™è¯¯ï¼šæœªèƒ½è§£æç›®å½•ç»“æ„æ ‡å‡†æ¸…å•æˆ–æ¸…å•ä¸ºç©ºã€‚è¯·æ£€æŸ¥ docs/01-è®¾è®¡/ç›®å½•ç»“æ„æ ‡å‡†æ¸…å•.md æ–‡ä»¶ã€‚")
            print("âŒ é”™è¯¯ï¼šæœªèƒ½è§£æç›®å½•ç»“æ„æ ‡å‡†æ¸…å•æˆ–æ¸…å•ä¸ºç©ºã€‚")
            self.warnings.append(
                "âš ï¸ æœªèƒ½ä»ç›®å½•ç»“æ„æ ‡å‡†æ¸…å•.mdåŠ è½½æ ‡å‡†ï¼Œæˆ–æ ‡å‡†æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œå°†ä½¿ç”¨å¤‡ç”¨ç¡¬ç¼–ç æ ‡å‡†ã€‚")
            self.standard_structure = get_fallback_structure()
            # å¦‚æœä½¿ç”¨ fallbackï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–ç™½åå•è·¯å¾„ä¸ºå°å†™
            raw_required_dirs_fallback = self.standard_structure.get(
                "required_dirs", [])
            raw_required_files_map_fallback = self.standard_structure.get(
                "required_files", {})
            self.whitelist_dirs_str_lower = set(
                d.lower() for d in raw_required_dirs_fallback)
            self.required_files_map_lower_keys = {
                k.lower(): v for k, v in raw_required_files_map_fallback.items()}
            self.whitelist_files_str_lower = set(
                self.required_files_map_lower_keys.keys())
            self.whitelist_dirs_pathobj = {
                Path(p) for p in self.whitelist_dirs_str_lower}
            self.whitelist_files_pathobj = {
                Path(p) for p in self.whitelist_files_str_lower}

    def check_all(self) -> Dict:
        """æ‰§è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print("ğŸ” å¼€å§‹æ£€æŸ¥é¡¹ç›®ç›®å½•ç»“æ„...")

        # ç™½åå•è·¯å¾„å·²åœ¨ __init__ ä¸­å¤„ç†ä¸ºå°å†™ Path å¯¹è±¡
        # whitelist_dirs_pathobj = self.whitelist_dirs_pathobj
        # whitelist_files_pathobj = self.whitelist_files_pathobj

        # 1. è·å–é¡¹ç›®ä¸­å®é™…å­˜åœ¨çš„æ‰€æœ‰æ–‡ä»¶å’Œç›®å½• (Pathå¯¹è±¡ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼Œä¸”å·²è½¬ä¸ºå°å†™)
        actual_project_paths_relative_lower = set()  # ä½¿ç”¨ set ç¡®ä¿å”¯ä¸€æ€§

        # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æ’é™¤ç›®å½•
        excluded_for_scan_entirely = set(
            CONFIG.get(
                'structure_check',
                {}).get(
                'excluded_dirs',
                [
                    '.git',
                    '.hg',
                    '.svn',
                    'node_modules',
                    '__pycache__',
                    '.pytest_cache',
                    '.mypy_cache',
                    'build',
                    'dist',
                    '*.egg-info']))
        self.info.append(
            f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶åŠ è½½æ’é™¤ç›®å½•: {
                ', '.join(excluded_for_scan_entirely)}")

        for path_object in self.project_root.rglob("*"):
            try:
                # è·å–ç›¸å¯¹è·¯å¾„å­—ç¬¦ä¸²å¹¶ç«‹å³è½¬ä¸ºå°å†™
                relative_path_str_lower = str(
                    path_object.relative_to(
                        self.project_root)).lower()
                # ä»å°å†™å­—ç¬¦ä¸²åˆ›å»º Path å¯¹è±¡
                relative_path_lower = Path(relative_path_str_lower)

                # æ£€æŸ¥æ˜¯å¦åœ¨å®Œå…¨æ’é™¤æ‰«æçš„ç›®å½•ä¸­ (åŸºäºå°å†™è·¯å¾„çš„parts)
                if any(
                        part.lower() in excluded_for_scan_entirely for part in relative_path_lower.parts):
                    continue

                actual_project_paths_relative_lower.add(relative_path_lower)

            except ValueError:
                continue  # å¿½ç•¥ä¸åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„è·¯å¾„

        # åˆ†åˆ«è·å–å®é™…çš„ç›®å½•å’Œæ–‡ä»¶é›†åˆ (åŸºäºå°å†™ Path å¯¹è±¡)
        actual_dirs_relative_lower = {
            p for p in actual_project_paths_relative_lower if (
                self.project_root / p).is_dir()}
        actual_files_relative_lower = {
            p for p in actual_project_paths_relative_lower if (
                self.project_root / p).is_file()}

        # 2. æ£€æŸ¥å¿…éœ€é¡¹æ˜¯å¦å­˜åœ¨ (ç™½åå•ä¸­çš„é¡¹æ˜¯å¦åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œå…¨éƒ¨ä½¿ç”¨å°å†™è·¯å¾„æ¯”è¾ƒ)
        self.check_required_directories(
            actual_dirs_relative_lower,
            self.whitelist_dirs_pathobj)
        self.check_required_files(
            actual_files_relative_lower,
            self.whitelist_files_pathobj)

        # 3. æ£€æŸ¥å†—ä½™é¡¹ (å®é™…é¡¹ç›®ä¸­çš„é¡¹æ˜¯å¦åœ¨ç™½åå•ä¸­ï¼Œå…¨éƒ¨ä½¿ç”¨å°å†™è·¯å¾„æ¯”è¾ƒ)
        # æ³¨æ„ï¼šä¼ é€’ç»™ check_redundant_items çš„ actual_project_paths_relative_lower
        # å·²ç»æ˜¯å°å†™ Path å¯¹è±¡é›†åˆ
        self.check_redundant_items(
            actual_project_paths_relative_lower,
            self.whitelist_dirs_pathobj,
            self.whitelist_files_pathobj)

        # 4. å…¶ä»–æ£€æŸ¥ (åªé’ˆå¯¹å®é™…å­˜åœ¨çš„ã€ä¸”æœªè¢«å®Œå…¨æ‰«ææ’é™¤çš„é¡¹)
        #    è·å–ç”¨äºå…¶ä»–æ£€æŸ¥çš„è·¯å¾„åˆ—è¡¨ (Pathå¯¹è±¡ï¼Œç»å¯¹è·¯å¾„ï¼Œä½†å…¶ç›¸å¯¹éƒ¨åˆ†å·²å°å†™åŒ–ä»¥ç”¨äºæ’é™¤æ£€æŸ¥)
        paths_for_other_checks = []
        print(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")

        # ç¡®ä¿å³ä½¿åœ¨å¿…éœ€ç›®å½•ç¼ºå¤±çš„æƒ…å†µä¸‹ï¼Œä¹Ÿä¼šç»§ç»­æ‰§è¡Œå‘½åè§„èŒƒå’Œç¦æ­¢é¡¹æ¨¡å¼çš„æ£€æŸ¥
        # ä½¿ç”¨å®é™…æ£€æŸ¥çš„ç›®å½•ï¼Œè€Œä¸æ˜¯PROJECT_ROOT
        for path_object in self.project_root.rglob("*"):
            try:
                # è·å–ç›¸å¯¹è·¯å¾„å­—ç¬¦ä¸²
                relative_path_str = str(
                    path_object.relative_to(
                        self.project_root))

                # æ£€æŸ¥æ˜¯å¦åœ¨å®Œå…¨æ’é™¤æ‰«æçš„ç›®å½•ä¸­
                if any(
                        part in excluded_for_scan_entirely for part in path_object.parts):
                    continue

                # æ·»åŠ è·¯å¾„åˆ°å…¶ä»–æ£€æŸ¥åˆ—è¡¨
                paths_for_other_checks.append(path_object)

            except ValueError:
                continue  # å¿½ç•¥ä¸åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„è·¯å¾„

        print(f"å…¶ä»–æ£€æŸ¥è·¯å¾„æ•°é‡: {len(paths_for_other_checks)}")
        if len(paths_for_other_checks) == 0:
            print("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è·¯å¾„è¿›è¡Œå…¶ä»–æ£€æŸ¥ï¼Œè¯·æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•æ˜¯å¦æ­£ç¡®ã€‚")

        # 5. ä¸“é—¨æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•è§„èŒƒ
        self.check_root_directory_compliance()

        self.check_forbidden_items(paths_for_other_checks)
        self.check_naming_conventions(paths_for_other_checks)
        self.check_file_content_basic()  # è¿™ä¸ªæ–¹æ³•ç›®å‰æ˜¯ pass

        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report()

        # ä¿å­˜æŠ¥å‘Š
        report_dir = self.project_root / \
            CONFIG['structure_check']['report_dir']
        report_filename_format = CONFIG['structure_check']['report_name_format']
        self.save_report(report, report_dir, report_filename_format)

        return report

    def check_required_directories(
            self,
            actual_dirs_relative_lower: set,
            whitelist_dirs_pathobj: set):
        """æ£€æŸ¥å¿…éœ€çš„ç›®å½• (ç™½åå•ä¸­çš„ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œä½¿ç”¨å°å†™è·¯å¾„æ¯”è¾ƒ)"""
        print("ğŸ“ æ£€æŸ¥å¿…éœ€ç›®å½• (ç™½åå•æ ¸å¯¹)...")
        for required_dir_path_obj_lower in whitelist_dirs_pathobj:  # å·²ç»æ˜¯å°å†™Pathå¯¹è±¡
            if required_dir_path_obj_lower not in actual_dirs_relative_lower:
                self.missing_items.append(
                    f"é¢„æœŸç›®å½•ç¼ºå¤±: {str(required_dir_path_obj_lower)}")
            else:
                self.info.append(
                    f"âœ… ç™½åå•ç›®å½•å­˜åœ¨: {
                        str(required_dir_path_obj_lower)}")

    def check_required_files(self,
                             actual_files_relative_lower: set,
                             whitelist_files_pathobj: set):
        """æ£€æŸ¥å¿…éœ€çš„æ–‡ä»¶ (ç™½åå•ä¸­çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä½¿ç”¨å°å†™è·¯å¾„æ¯”è¾ƒ)"""
        print("ğŸ“„ æ£€æŸ¥å¿…éœ€æ–‡ä»¶ (ç™½åå•æ ¸å¯¹)...")
        for required_file_path_obj_lower in whitelist_files_pathobj:  # å·²ç»æ˜¯å°å†™Pathå¯¹è±¡
            # ä» self.required_files_map_lower_keys è·å–æè¿°ï¼Œé”®æ˜¯å°å†™è·¯å¾„å­—ç¬¦ä¸²
            description = self.required_files_map_lower_keys.get(
                str(required_file_path_obj_lower), "é¡¹ç›®æ–‡ä»¶")

            if required_file_path_obj_lower not in actual_files_relative_lower:
                self.missing_items.append(
                    f"é¢„æœŸæ–‡ä»¶ç¼ºå¤±: {
                        str(required_file_path_obj_lower)} ({description})")
            elif (self.project_root / required_file_path_obj_lower).stat().st_size == 0:
                self.warnings.append(
                    f"æ–‡ä»¶ä¸ºç©º: {
                        str(required_file_path_obj_lower)}")
            else:
                self.info.append(
                    f"âœ… ç™½åå•æ–‡ä»¶å­˜åœ¨ä¸”éç©º: {
                        str(required_file_path_obj_lower)}")

    def check_redundant_items(
            self,
            actual_project_paths_relative_lower: set,
            whitelist_dirs_pathobj: set,
            whitelist_files_pathobj: set):
        """æ£€æŸ¥å†—ä½™é¡¹ (å®é™…å­˜åœ¨ä½†ä¸åœ¨ç™½åå•ä¸­çš„é¡¹ï¼Œä½¿ç”¨å°å†™è·¯å¾„æ¯”è¾ƒ)"""
        print("ğŸ—‘ï¸  æ£€æŸ¥å†—ä½™é¡¹ (éç™½åå•å†…å®¹)...")

        # excluded_dirs_for_redundancy_check ä¸­çš„é¡¹ä¹Ÿåº”è¯¥ç”¨å°å†™æ¯”è¾ƒ
        excluded_dirs_for_redundancy_check_lower = {
            d.lower() for d in self.excluded_dirs_for_redundancy_check}

        for actual_path_obj_lower in actual_project_paths_relative_lower:  # å·²ç»æ˜¯å°å†™Pathå¯¹è±¡
            is_in_excluded_for_redundancy = False
            if actual_path_obj_lower.parts:
                # actual_path_obj_lower.parts[0] å·²ç»æ˜¯å°å†™
                if actual_path_obj_lower.parts[0] in excluded_dirs_for_redundancy_check_lower:
                    is_in_excluded_for_redundancy = True

            if is_in_excluded_for_redundancy:
                continue

            # ä½¿ç”¨ self.project_root / actual_path_obj_lower æ¥æ£€æŸ¥å®é™…æ–‡ä»¶ç³»ç»Ÿä¸­çš„é¡¹
            # å› ä¸º actual_path_obj_lower æ˜¯å°å†™çš„ï¼Œè€Œæ–‡ä»¶ç³»ç»Ÿä¸Šçš„åŸå§‹è·¯å¾„å¯èƒ½æœ‰å¤§å†™
            # ä½† is_dir() / is_file() åœ¨Windowsä¸Šé€šå¸¸ä¸åŒºåˆ†å¤§å°å†™ï¼Œæ‰€ä»¥è¿™é‡Œåº”è¯¥æ²¡é—®é¢˜
            # ä¸ºäº†æ›´ä¸¥è°¨ï¼Œåº”è¯¥ç”¨åŸå§‹å¤§å°å†™çš„è·¯å¾„å»is_dir/is_fileï¼Œä½†æˆ‘ä»¬è¿™é‡Œåªæœ‰å°å†™è·¯å¾„
            # æ›´å¥½çš„åšæ³•æ˜¯åœ¨æ”¶é›† actual_project_paths_relative æ—¶åŒæ—¶ä¿å­˜åŸå§‹å¤§å°å†™è·¯å¾„å’Œå¯¹åº”çš„å°å†™è·¯å¾„
            # ä½†ç›®å‰ä¸ºäº†ç®€åŒ–ï¼Œå…ˆå‡è®¾ is_dir/is_file åœ¨å°å†™è·¯å¾„ä¸Šèƒ½æ­£ç¡®å·¥ä½œ
            is_dir = (self.project_root / actual_path_obj_lower).is_dir()
            is_file = (self.project_root / actual_path_obj_lower).is_file()

            is_redundant = False
            if is_dir:
                if actual_path_obj_lower not in whitelist_dirs_pathobj:
                    is_redundant = True
            elif is_file:
                if actual_path_obj_lower not in whitelist_files_pathobj:
                    is_redundant = True

            if is_redundant:
                item_type = "ç›®å½•" if is_dir else "æ–‡ä»¶"
                # æ·»åŠ åˆ° set çš„å†—ä½™ä¿¡æ¯å­—ç¬¦ä¸²ä¸­çš„è·¯å¾„ä¹Ÿä½¿ç”¨å°å†™
                redundancy_msg = f"å†—ä½™{item_type}: {str(actual_path_obj_lower)}"
                self.redundant_items.add(redundancy_msg)

    def check_forbidden_items(self, paths_to_check: list):
        """æ£€æŸ¥ç¦æ­¢é¡¹ (ä¾‹å¦‚ .tmp, .bak æ–‡ä»¶)"""
        print("ğŸš« æ£€æŸ¥ç¦æ­¢é¡¹...")
        print(f"å¾…æ£€æŸ¥è·¯å¾„æ•°é‡: {len(paths_to_check)}")
        forbidden_patterns = self.standard_structure.get(
            "forbidden_patterns", [])
        if not forbidden_patterns:
            # å¦‚æœæ²¡æœ‰å®šä¹‰ç¦æ­¢æ¨¡å¼ï¼Œä»é…ç½®æ–‡ä»¶ä¸­è¯»å–é»˜è®¤çš„ç¦æ­¢æ¨¡å¼
            default_forbidden_patterns = CONFIG.get('structure_check', {}).get('default_forbidden_patterns', [
                "*.tmp",   # ä¸´æ—¶æ–‡ä»¶
                "*.bak",   # å¤‡ä»½æ–‡ä»¶
                "*.swp",   # vimäº¤æ¢æ–‡ä»¶
                "*.log",   # æ—¥å¿—æ–‡ä»¶
                "*~",      # ä¸´æ—¶å¤‡ä»½æ–‡ä»¶
                "Thumbs.db",  # Windowsç¼©ç•¥å›¾æ•°æ®åº“
                ".DS_Store"  # macOSç›®å½•å…ƒæ•°æ®
            ])
            forbidden_patterns = default_forbidden_patterns
            self.info.append(
                f"âš ï¸ æœªåœ¨æ ‡å‡†æ–‡ä»¶ä¸­å®šä¹‰ç¦æ­¢é¡¹æ¨¡å¼ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤ç¦æ­¢æ¨¡å¼: {
                    ', '.join(forbidden_patterns)}")
            print(
                f"âš ï¸ æœªåœ¨æ ‡å‡†æ–‡ä»¶ä¸­å®šä¹‰ç¦æ­¢é¡¹æ¨¡å¼ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤ç¦æ­¢æ¨¡å¼: {
                    ', '.join(forbidden_patterns)}")

        print(f"ç¦æ­¢é¡¹æ¨¡å¼: {forbidden_patterns}")
        found_forbidden_items = False
        forbidden_items_count = 0

        if not paths_to_check:
            print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ£€æŸ¥çš„è·¯å¾„")
            return

        print("\nå¼€å§‹é€ä¸ªæ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ…å«ç¦æ­¢é¡¹...")
        print("=" * 50)

        for i, path_obj in enumerate(paths_to_check):
            print(f"\næ£€æŸ¥ç¬¬{i + 1}ä¸ªè·¯å¾„: {path_obj}")
            try:
                path_str = str(path_obj.relative_to(self.project_root))
                print(f"ç›¸å¯¹è·¯å¾„: {path_str}")

                # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•ç¦æ­¢æ¨¡å¼
                matched_patterns = []
                for pattern in forbidden_patterns:
                    print(f"æ£€æŸ¥æ¨¡å¼: {pattern}")
                    match_path = fnmatch.fnmatch(
                        path_str.lower(), pattern.lower())
                    match_name = fnmatch.fnmatch(
                        path_obj.name.lower(), pattern.lower())
                    print(f"  è·¯å¾„åŒ¹é…ç»“æœ: {match_path}, æ–‡ä»¶ååŒ¹é…ç»“æœ: {match_name}")

                    if match_path or match_name:
                        matched_patterns.append(pattern)

                if matched_patterns:
                    issue_msg = f"å‘ç°ç¦æ­¢é¡¹: {
                        path_obj.relative_to(
                            self.project_root)} (åŒ¹é…æ¨¡å¼: {
                        ', '.join(matched_patterns)})"
                    self.issues.append(issue_msg)
                    print(f"âŒ {issue_msg}")
                    found_forbidden_items = True
                    forbidden_items_count += 1
                else:
                    print(f"âœ… æœªå‘ç°ç¦æ­¢é¡¹: {path_str}")
            except ValueError as e:
                # å¦‚æœè·¯å¾„ä¸åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œè·³è¿‡
                print(f"æ— æ³•è·å–ç›¸å¯¹è·¯å¾„: {path_obj}ï¼Œé”™è¯¯: {e}")
                continue

        print("\n" + "=" * 50)
        print("ç¦æ­¢é¡¹æ£€æŸ¥ç»“æœæ±‡æ€»:")

        if found_forbidden_items:
            print(f"å‘ç°ç¦æ­¢é¡¹é—®é¢˜ï¼Œæ€»è®¡: {forbidden_items_count}ä¸ªä¸¥é‡é—®é¢˜")
            print("é”™è¯¯åˆ—è¡¨:")
            for i, error in enumerate(
                    [e for e in self.issues if "å‘ç°ç¦æ­¢é¡¹" in e]):
                print(f"  {i + 1}. {error}")
        else:
            print("æœªå‘ç°ç¦æ­¢é¡¹é—®é¢˜")

        print(f"ç¦æ­¢é¡¹æ£€æŸ¥å®Œæˆï¼Œä¸¥é‡é—®é¢˜æ€»æ•°: {forbidden_items_count}")

    def check_root_directory_compliance(self):
        """æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•è§„èŒƒåˆè§„æ€§"""
        print("ğŸ  æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•è§„èŒƒåˆè§„æ€§...")

        # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æ ¹ç›®å½•è§„åˆ™
        root_rules = CONFIG.get(
            'structure_check', {}).get(
            'root_directory_rules', {})
        if not root_rules:
            self.warnings.append("âš ï¸ æœªé…ç½®æ ¹ç›®å½•æ£€æŸ¥è§„åˆ™ï¼Œè·³è¿‡æ ¹ç›®å½•è§„èŒƒæ£€æŸ¥")
            return

        allowed_directories = set(root_rules.get('allowed_directories', []))
        forbidden_dir_patterns = root_rules.get(
            'forbidden_directory_patterns', [])
        forbidden_file_patterns = root_rules.get('forbidden_file_patterns', [])

        print(f"å…è®¸çš„æ ¹ç›®å½•: {', '.join(allowed_directories)}")
        print(f"ç¦æ­¢çš„ç›®å½•æ¨¡å¼: {', '.join(forbidden_dir_patterns)}")
        print(f"ç¦æ­¢çš„æ–‡ä»¶æ¨¡å¼: {', '.join(forbidden_file_patterns)}")

        # æ£€æŸ¥æ ¹ç›®å½•ä¸‹çš„ç›´æ¥å­é¡¹
        root_violations = []

        try:
            for item in self.project_root.iterdir():
                item_name = item.name

                if item.is_dir():
                    # æ£€æŸ¥ç›®å½•æ˜¯å¦åœ¨å…è®¸åˆ—è¡¨ä¸­
                    if item_name not in allowed_directories:
                        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç¦æ­¢æ¨¡å¼
                        is_forbidden = False
                        for pattern in forbidden_dir_patterns:
                            if fnmatch.fnmatch(
                                    item_name.lower(), pattern.lower()):
                                is_forbidden = True
                                root_violations.append(
                                    f"æ ¹ç›®å½•ç¦æ­¢ç›®å½•: {item_name} (åŒ¹é…æ¨¡å¼: {pattern})")
                                break

                        if not is_forbidden:
                            root_violations.append(
                                f"æ ¹ç›®å½•éæ ‡å‡†ç›®å½•: {item_name} (ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­)")
                    else:
                        self.info.append(f"âœ… æ ¹ç›®å½•æ ‡å‡†ç›®å½•: {item_name}")

                elif item.is_file():
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ¹é…ç¦æ­¢æ¨¡å¼
                    for pattern in forbidden_file_patterns:
                        if fnmatch.fnmatch(item_name.lower(), pattern.lower()):
                            root_violations.append(
                                f"æ ¹ç›®å½•ç¦æ­¢æ–‡ä»¶: {item_name} (åŒ¹é…æ¨¡å¼: {pattern})")
                            break
                    else:
                        # æ ¹ç›®å½•ä¸€èˆ¬ä¸åº”è¯¥æœ‰æ–‡ä»¶ï¼ˆé™¤äº†ç‰¹æ®Šæƒ…å†µå¦‚READMEç­‰ï¼‰
                        if item_name.lower() not in [
                                'readme.md', 'readme.txt', '.gitignore', 'license']:
                            root_violations.append(
                                f"æ ¹ç›®å½•ä¸è§„èŒƒæ–‡ä»¶: {item_name} (å»ºè®®ç§»è‡³é€‚å½“ç›®å½•)")

        except Exception as e:
            self.warnings.append(f"âš ï¸ æ£€æŸ¥æ ¹ç›®å½•æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return

        # è®°å½•è¿è§„é¡¹
        if root_violations:
            for violation in root_violations:
                self.issues.append(f"æ ¹ç›®å½•è§„èŒƒè¿è§„: {violation}")
            print(f"âŒ å‘ç° {len(root_violations)} ä¸ªæ ¹ç›®å½•è§„èŒƒè¿è§„")
        else:
            self.info.append("âœ… æ ¹ç›®å½•è§„èŒƒæ£€æŸ¥é€šè¿‡")
            print("âœ… æ ¹ç›®å½•è§„èŒƒæ£€æŸ¥é€šè¿‡")

    def check_naming_conventions(self, paths_to_check: list):
        """æ£€æŸ¥å‘½åè§„èŒƒ"""
        print("ğŸ·ï¸ æ£€æŸ¥å‘½åè§„èŒƒ...")
        print(f"å¾…æ£€æŸ¥è·¯å¾„æ•°é‡: {len(paths_to_check)}")
        naming_rules = self.standard_structure.get("naming_rules", {})
        if not naming_rules:
            self.info.append("âš ï¸ æœªå®šä¹‰å‘½åè§„èŒƒï¼Œè·³è¿‡å‘½åè§„èŒƒæ£€æŸ¥")
            print("âš ï¸ æœªå®šä¹‰å‘½åè§„èŒƒï¼Œè·³è¿‡å‘½åè§„èŒƒæ£€æŸ¥")
            return

        print(f"å‘½åè§„èŒƒ: {naming_rules}")

        # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–é»˜è®¤çš„å‘½åè§„åˆ™
        default_naming_rules = CONFIG.get(
            'structure_check', {}).get(
            'default_naming_rules', {})

        # å®šä¹‰å„ç±»æ–‡ä»¶çš„æ­£åˆ™è¡¨è¾¾å¼è§„åˆ™
        rules = {
            "docs": {
                "pattern": default_naming_rules.get(
                    "docs",
                    r"^[\u4e00-\u9fa5a-zA-Z0-9_\-\s\.]+\.(md|txt|docx|pdf)$"),
                "description": "æ–‡æ¡£æ–‡ä»¶åº”ä½¿ç”¨ä¸­æ–‡å‘½åï¼Œå¯åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€çŸ­æ¨ªçº¿å’Œç©ºæ ¼"},
            "code": {
                "pattern": default_naming_rules.get(
                    "tools",
                    r"^[a-z][a-z0-9_]*\.[a-z0-9_]+$"),
                "description": "ä»£ç æ–‡ä»¶åº”ä½¿ç”¨å°å†™å­—æ¯å’Œä¸‹åˆ’çº¿(snake_case)ï¼Œä»¥å­—æ¯å¼€å¤´"},
            "config": {
                "pattern": default_naming_rules.get(
                    "config",
                    r"^[a-z0-9_\-\.]+$"),
                "description": "é…ç½®æ–‡ä»¶åº”ä½¿ç”¨å°å†™å­—æ¯ï¼Œå¯åŒ…å«æ•°å­—ã€ä¸‹åˆ’çº¿ã€çŸ­æ¨ªçº¿å’Œç‚¹"},
            "directory": {
                "pattern": r"^[a-z0-9_\-\u4e00-\u9fa5\s]+$",
                "description": "ç›®å½•åº”ä½¿ç”¨å°å†™å­—æ¯å’Œä¸‹åˆ’çº¿ï¼Œæˆ–ä¸­æ–‡å‘½åï¼Œå¯åŒ…å«æ•°å­—ã€çŸ­æ¨ªçº¿å’Œç©ºæ ¼"}}

        self.info.append(f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶åŠ è½½å‘½åè§„åˆ™: {default_naming_rules}")

        print(f"æ­£åˆ™è¡¨è¾¾å¼è§„åˆ™: {rules}")

        # æ–‡ä»¶æ‰©å±•ååˆ†ç±»
        doc_extensions = [
            ".md",
            ".txt",
            ".docx",
            ".pd",
            ".xlsx",
            ".pptx",
            ".csv"]
        code_extensions = [
            ".py",
            ".js",
            ".ts",
            ".html",
            ".css",
            ".java",
            ".c",
            ".cpp",
            ".h",
            ".go",
            ".rs",
            ".php",
            ".sh",
            ".bat",
            ".ps1"]
        config_extensions = [
            ".yaml",
            ".yml",
            ".json",
            ".toml",
            ".ini",
            ".con",
            ".config",
            ".env"]

        print("æ–‡ä»¶æ‰©å±•ååˆ†ç±»:")
        print(f"  æ–‡æ¡£æ–‡ä»¶: {doc_extensions}")
        print(f"  ä»£ç æ–‡ä»¶: {code_extensions}")
        print(f"  é…ç½®æ–‡ä»¶: {config_extensions}")

        # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–è·³è¿‡æ£€æŸ¥çš„ç›®å½•
        skip_dirs = CONFIG.get(
            'structure_check', {}).get(
            'excluded_dirs', [
                "bak", "logs", ".git", ".vscode", "__pycache__", "node_modules"])
        print(f"è·³è¿‡æ£€æŸ¥çš„ç›®å½•: {skip_dirs}")
        self.info.append(f"ğŸ“‹ å‘½åè§„èŒƒæ£€æŸ¥è·³è¿‡ç›®å½•: {', '.join(skip_dirs)}")

        found_naming_issues = False
        naming_warnings_count = 0

        if not paths_to_check:
            print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ£€æŸ¥çš„è·¯å¾„")
            return

        print("\nå¼€å§‹é€ä¸ªæ£€æŸ¥è·¯å¾„çš„å‘½åè§„èŒƒ...")
        print("=" * 50)

        for i, path_obj in enumerate(paths_to_check):
            print(f"\næ£€æŸ¥ç¬¬{i + 1}ä¸ªè·¯å¾„: {path_obj}")
            try:
                rel_path = path_obj.relative_to(self.project_root)

                # è·³è¿‡ç‰¹å®šç›®å½•ä¸‹çš„æ–‡ä»¶æ£€æŸ¥
                if any(part.lower() in skip_dirs for part in rel_path.parts):
                    print(f"è·³è¿‡è·¯å¾„: {rel_path} (åœ¨è·³è¿‡æ£€æŸ¥çš„ç›®å½•ä¸­)")
                    continue

                print(f"æ£€æŸ¥è·¯å¾„: {rel_path}")

                if path_obj.is_dir():
                    rule = rules["directory"]
                    print(f"ç›®å½•æ£€æŸ¥: {path_obj.name}, ä½¿ç”¨è§„åˆ™: {rule['pattern']}")
                    match_result = re.match(rule["pattern"], path_obj.name)
                    print(f"åŒ¹é…ç»“æœ: {match_result is not None}")

                    if not match_result:
                        warning_msg = f"ç›®å½•å‘½åä¸è§„èŒƒ: {rel_path} ({
                            rule['description']})"
                        self.warnings.append(warning_msg)
                        print(f"âš ï¸ {warning_msg}")
                        found_naming_issues = True
                        naming_warnings_count += 1
                    else:
                        print(f"âœ… ç›®å½•å‘½åè§„èŒƒ: {rel_path}")
                elif path_obj.is_file():
                    ext = path_obj.suffix.lower()
                    print(f"æ–‡ä»¶æ‰©å±•å: {ext}")

                    if ext in doc_extensions:
                        rule = rules["docs"]
                        print(f"æ–‡æ¡£æ–‡ä»¶: {rel_path}, ä½¿ç”¨è§„åˆ™: {rule['pattern']}")
                    elif ext in code_extensions:
                        rule = rules["code"]
                        print(f"ä»£ç æ–‡ä»¶: {rel_path}, ä½¿ç”¨è§„åˆ™: {rule['pattern']}")
                    elif ext in config_extensions:
                        rule = rules["config"]
                        print(f"é…ç½®æ–‡ä»¶: {rel_path}, ä½¿ç”¨è§„åˆ™: {rule['pattern']}")
                    else:
                        print(f"æœªçŸ¥ç±»å‹æ–‡ä»¶: {rel_path}ï¼Œè·³è¿‡æ£€æŸ¥")
                        continue

                    # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ç¬¦åˆè§„åˆ™
                    print(f"æ£€æŸ¥æ–‡ä»¶å: {path_obj.name}")
                    match_result = re.match(rule["pattern"], path_obj.name)
                    print(f"åŒ¹é…ç»“æœ: {match_result is not None}")

                    if not match_result:
                        warning_msg = f"æ–‡ä»¶å‘½åä¸è§„èŒƒ: {rel_path} ({
                            rule['description']})"
                        self.warnings.append(warning_msg)
                        print(f"âš ï¸ {warning_msg}")
                        found_naming_issues = True
                        naming_warnings_count += 1
                    else:
                        print(f"âœ… æ–‡ä»¶å‘½åè§„èŒƒ: {rel_path}")
            except ValueError as e:
                print(f"æ— æ³•è·å–ç›¸å¯¹è·¯å¾„: {path_obj}ï¼Œé”™è¯¯: {e}")
                continue

        print("\n" + "=" * 50)
        print("å‘½åè§„èŒƒæ£€æŸ¥ç»“æœæ±‡æ€»:")

        if found_naming_issues:
            print(f"å‘ç°å‘½åè§„èŒƒé—®é¢˜ï¼Œæ€»è®¡: {naming_warnings_count}ä¸ªè­¦å‘Š")
            print("è­¦å‘Šåˆ—è¡¨:")
            for i, warning in enumerate(
                    [w for w in self.warnings if "å‘½åä¸è§„èŒƒ" in w]):
                print(f"  {i + 1}. {warning}")
        else:
            print("æœªå‘ç°å‘½åè§„èŒƒé—®é¢˜")

        print(f"å‘½åè§„èŒƒæ£€æŸ¥å®Œæˆï¼Œè­¦å‘Šæ€»æ•°: {naming_warnings_count}")

    def check_file_content_basic(self):
        """åŸºç¡€æ–‡ä»¶å†…å®¹æ£€æŸ¥ (ä¾‹å¦‚, æ£€æŸ¥å¿…éœ€æ–‡ä»¶æ˜¯å¦ä¸ºç©º) - éƒ¨åˆ†å·²ç§»è‡³ check_required_files"""
        print("ğŸ“œ åŸºç¡€æ–‡ä»¶å†…å®¹æ£€æŸ¥ (å½“å‰è·³è¿‡)...")
        # éƒ¨åˆ†é€»è¾‘å·²åœ¨ check_required_files ä¸­å¤„ç†ç©ºæ–‡ä»¶çš„æƒ…å†µ
        # æ­¤å¤„å¯ä»¥ä¿ç•™ç”¨äºæœªæ¥æ›´å¤æ‚çš„å†…å®¹æ£€æŸ¥ï¼Œä¾‹å¦‚ç‰¹å®šæ ‡è®°æˆ–å¤´éƒ¨ä¿¡æ¯
        pass

    def generate_report(self) -> Dict:
        """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
        total_issues = len(self.issues)
        total_warnings = len(self.warnings)
        total_redundant = len(self.redundant_items)
        total_missing = len(self.missing_items)
        total_info = len(self.info)

        # è®¡ç®—å¾—åˆ†ï¼Œæ›´ç»†è‡´çš„æ‰£åˆ†ç­–ç•¥
        score = 100
        score -= total_issues * 15  # æ¯ä¸ªä¸¥é‡é—®é¢˜æ‰£15åˆ†
        score -= total_redundant * 10  # æ¯ä¸ªå†—ä½™é¡¹æ‰£10åˆ†
        score -= total_warnings * 5   # æ¯ä¸ªè­¦å‘Šæ‰£5åˆ†
        score -= total_missing * 2    # æ¯ä¸ªç¼ºå¤±é¡¹æ‰£2åˆ† (è½»å¾®)
        score = max(0, score)  # æœ€ä½0åˆ†

        # ç¡®å®šçŠ¶æ€ï¼Œæ›´æ¸…æ™°çš„çŠ¶æ€å±‚çº§
        if total_issues > 0 or total_redundant > 0:
            status_icon = "âŒ"
            status_text = "æ£€æŸ¥å¤±è´¥"
            if total_issues > 0 and total_redundant > 0:
                status_detail = "å­˜åœ¨ä¸¥é‡é—®é¢˜å’Œå†—ä½™é¡¹"
            elif total_issues > 0:
                status_detail = "å­˜åœ¨ä¸¥é‡é—®é¢˜"
            else:
                status_detail = "å­˜åœ¨å†—ä½™é¡¹"
        elif total_warnings > 0:
            status_icon = "âš ï¸"
            status_text = "é€šè¿‡ä½†æœ‰è­¦å‘Š"
            status_detail = "å­˜åœ¨è­¦å‘Šä¿¡æ¯"
        elif total_missing > 0:
            status_icon = "â„¹ï¸"
            status_text = "é€šè¿‡ä½†æœ‰ç¼ºå¤±é¡¹"
            status_detail = "å­˜åœ¨é¢„æœŸä½†ç¼ºå¤±çš„é¡¹"
        else:
            status_icon = "âœ…"
            status_text = "å®Œå…¨é€šè¿‡"
            status_detail = "æ‰€æœ‰æ£€æŸ¥é¡¹ç¬¦åˆæ ‡å‡†"

        final_status = f"{status_icon} {status_text} - {status_detail}"
        if total_missing > 0 and (
                total_issues == 0 and total_redundant == 0 and total_warnings == 0):
            final_status = f"{status_icon} {status_text} - {status_detail} (è¯·æ³¨æ„è¡¥å……ç¼ºå¤±é¡¹)"
        elif total_missing > 0 and total_warnings > 0 and (total_issues == 0 and total_redundant == 0):
            final_status = f"{status_icon} {status_text} - {status_detail} (è¯·æ³¨æ„è¡¥å……ç¼ºå¤±é¡¹å’Œå¤„ç†è­¦å‘Š)"

        # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æ ‡å‡†æ¸…å•æ–‡ä»¶è·¯å¾„
        standard_list_file = CONFIG.get(
            'structure_check', {}).get(
            'standard_list_file', 'docs/01-è®¾è®¡/ç›®å½•ç»“æ„æ ‡å‡†æ¸…å•.md')
        standard_file_path = PROJECT_ROOT / standard_list_file

        report = {
            "check_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "project_root_checked": str(self.project_root),
            "standard_file_used": str(standard_file_path),
            "overall_status": final_status,
            "final_score": score,
            "summary_counts": {
                "total_issues": total_issues,
                "total_warnings": total_warnings,
                "total_redundant_items": total_redundant,
                "total_missing_items": total_missing,
                "total_info_logs": total_info,
                "total_items_scanned": total_issues + total_warnings + total_redundant + total_missing + total_info  # ç²—ç•¥ä¼°è®¡æ‰«æç‚¹
            },
            "detailed_findings": {
                "critical_issues": self.issues,
                "improvement_warnings": self.warnings,
                "unnecessary_items": sorted(list(self.redundant_items)),
                "missing_required_items": self.missing_items,
                "informational_logs": self.info,
            },
        }
        return report

    def save_report(
            self,
            report: Dict,
            report_dir: Path,
            report_filename_format: str):
        """ä¿å­˜æ£€æŸ¥æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        try:
            report_dir.mkdir(parents=True, exist_ok=True)
            # ä»æŠ¥å‘Šå†…éƒ¨è·å–æ—¶é—´æˆ³ï¼Œç¡®ä¿æ–‡ä»¶åä¸æŠ¥å‘Šå†…å®¹ä¸€è‡´
            report_timestamp_str = datetime.strptime(
                report["check_timestamp"],
                "%Y-%m-%d %H:%M:%S").strftime("%Y%m%d_%H%M%S")

            if "{timestamp}" in report_filename_format:
                report_file_name = report_filename_format.format(
                    timestamp=report_timestamp_str)
            elif "{status}" in report_filename_format:  # å¢åŠ æŒ‰çŠ¶æ€ä¿å­˜çš„é€‰é¡¹
                # ä» overall_status ä¸­æå–ä¸€ä¸ªç®€çŸ­çš„çŠ¶æ€æè¿°ä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†
                # ä¾‹å¦‚ "âŒ æ£€æŸ¥å¤±è´¥ - å­˜åœ¨ä¸¥é‡é—®é¢˜" -> "æ£€æŸ¥å¤±è´¥"
                status_for_filename = report["overall_status"].split(
                    " - ")[0].split(" ")[-1]  # å–æœ€åä¸€ä¸ªè¯
                base, ext = os.path.splitext(
                    report_filename_format.format(
                        status=status_for_filename))
                report_file_name = f"{base}_{report_timestamp_str}{ext}"
            else:
                base, ext = os.path.splitext(report_filename_format)
                report_file_name = f"{base}_{report_timestamp_str}{ext}"

            report_file_path = report_dir / report_file_name

            with open(report_file_path, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=4)

            success_msg = f"ğŸ“ ç»“æ„æ£€æŸ¥æŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³: {report_file_path}"
            print(success_msg)
            # é¿å…åœ¨ä¿å­˜æŠ¥å‘ŠæˆåŠŸåä¿®æ”¹æŠ¥å‘Šå†…å®¹ (self.info)
            # self.info.append(success_msg) # ç§»è‡³è°ƒç”¨æ–¹æˆ–æ—¥å¿—æ¨¡å—å¤„ç†
            return str(report_file_path)  # è¿”å›ä¿å­˜çš„è·¯å¾„

        except KeyError as e:
            error_msg = f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: æŠ¥å‘Šæ•°æ®ä¸­ç¼ºå°‘é”® '{e}'ã€‚è¯·æ£€æŸ¥ generate_report æ–¹æ³•ã€‚"
            print(error_msg)
            self.issues.append(error_msg)
            return None
        except IOError as e:
            error_msg = f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: æ— æ³•å†™å…¥æ–‡ä»¶ã€‚IOé”™è¯¯: {e}"
            print(error_msg)
            self.issues.append(error_msg)
            return None
        except Exception as e:
            error_msg = f"âŒ ä¿å­˜æŠ¥å‘Šæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"
            print(error_msg)
            self.issues.append(error_msg)
            import traceback
            traceback.print_exc()  # æ‰“å°è¯¦ç»†å †æ ˆä¿¡æ¯ä»¥ä¾›è°ƒè¯•
            return None

    def format_report_for_console(self, report: Dict) -> str:
        """æ ¼å¼åŒ–æŠ¥å‘Šä¸ºæ§åˆ¶å°å¯è¯»æ–‡æœ¬ï¼Œæ›´ç®€æ´"""
        lines = []
        lines.append("\n" + "=" * 70)
        lines.append("========   3AIå·¥ä½œå®¤ - é¡¹ç›®ç»“æ„å¥åº·æ£€æŸ¥æŠ¥å‘Š   ========")
        lines.append("=" * 70)
        lines.append(f"æ£€æŸ¥æ—¶é—´:         {report['check_timestamp']}")
        lines.append(f"é¡¹ç›®æ ¹ç›®å½•:       {report['project_root_checked']}")
        lines.append(f"éµå¾ªæ ‡å‡†:         {report['standard_file_used']}")
        lines.append(f"ç»¼åˆè¯„ä¼°:         {report['overall_status']}")
        lines.append(f"å¥åº·æŒ‡æ•°:         {report['final_score']}/100")
        lines.append("-" * 70)

        summary = report["summary_counts"]
        lines.append("ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡ç»Ÿè®¡:")
        lines.append(
            f"  - ğŸ”´ ä¸¥é‡é—®é¢˜ (Critical Issues):      {summary['total_issues']}")
        lines.append(
            f"  - ğŸŸ¡ æ”¹è¿›è­¦å‘Š (Improvement Warnings): {summary['total_warnings']}")
        lines.append(
            f"  - ğŸ—‘ï¸ å†—ä½™é¡¹ (Unnecessary Items):      {summary['total_redundant_items']}")
        lines.append(
            f"  - â„¹ï¸ ç¼ºå¤±é¡¹ (Missing Required):      {summary['total_missing_items']}")
        lines.append(
            f"  - ğŸ“‹ ä¿¡æ¯è®°å½• (Info Logs):          {summary['total_info_logs']}")
        lines.append(
            f"  - ğŸ” æ€»æ‰«æç‚¹ (Estimated Scanned): {summary['total_items_scanned']}")
        lines.append("-" * 70)

        details = report["detailed_findings"]

        if details["critical_issues"]:
            lines.append("ğŸ”´ ä¸¥é‡é—®é¢˜ (Critical Issues - éœ€ç«‹å³å¤„ç†):")
            for idx, issue in enumerate(details["critical_issues"], 1):
                lines.append(f"  {idx}. {issue}")
            lines.append("")

        if details["unnecessary_items"]:
            lines.append("ğŸ—‘ï¸ å†—ä½™é¡¹ (Unnecessary Items - å»ºè®®æ¸…ç†):")
            for idx, item in enumerate(details["unnecessary_items"], 1):
                lines.append(f"  {idx}. {item}")
            lines.append("")

        if details["improvement_warnings"]:
            lines.append("ğŸŸ¡ æ”¹è¿›è­¦å‘Š (Improvement Warnings - å»ºè®®å…³æ³¨):")
            for idx, warning in enumerate(details["improvement_warnings"], 1):
                lines.append(f"  {idx}. {warning}")
            lines.append("")

        if details["missing_required_items"]:
            lines.append("â„¹ï¸ é¢„æœŸä½†ç¼ºå¤±çš„é¡¹ (Missing Required Items - è¯·è¡¥å……):")
            for idx, item in enumerate(details["missing_required_items"], 1):
                lines.append(f"  {idx}. {item}")
            lines.append("")

        # ä¿¡æ¯è®°å½•é€šå¸¸ç”¨äºè°ƒè¯•æˆ–ç¡®è®¤ï¼Œé»˜è®¤ä¸åœ¨æ§åˆ¶å°å¤§é‡è¾“å‡ºï¼Œé™¤éæœ‰ç‰¹æ®Šéœ€è¦
        # if details["informational_logs"]:
        #     lines.append("ğŸ“‹ ä¿¡æ¯è®°å½• (Informational Logs):")
        #     for idx, info_log in enumerate(details["informational_logs"], 1):
        #         lines.append(f"  {idx}. {info_log}")
        #     lines.append("")

        lines.append("=" * 70)
        lines.append("========             æŠ¥å‘Šç»“æŸ             ========")
        lines.append("=" * 70 + "\n")

        return "\n".join(lines)

    def print_report_to_console(self, report: Dict):
        """å°†æ ¼å¼åŒ–åçš„æŠ¥å‘Šæ‰“å°åˆ°æ§åˆ¶å°"""
        formatted_report_text = self.format_report_for_console(report)
        print(formatted_report_text)


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        import argparse
        parser = argparse.ArgumentParser(description="3AIå·¥ä½œå®¤ç›®å½•ç»“æ„æ£€æŸ¥å·¥å…·")
        parser.add_argument(
            "project_path",
            nargs="?",
            default=".",
            help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„")
        parser.add_argument(
            "--only-check-forbidden",
            action="store_true",
            help="ä»…æ£€æŸ¥ç¦æ­¢é¡¹")
        parser.add_argument(
            "--report-only",
            action="store_true",
            help="ä»…ç”ŸæˆæŠ¥å‘Šï¼Œä¸æ‰§è¡Œæ£€æŸ¥")
        parser.add_argument("--verbose", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†è¾“å‡º")
        args = parser.parse_args()

        # ä½¿ç”¨ä¼ å…¥çš„è·¯å¾„ï¼Œå¦‚æœå®ƒæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œåˆ™ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•è§£æ
        project_root_abs = Path(args.project_path).resolve()
        if not project_root_abs.is_dir():
            print(
                f"âŒé”™è¯¯ï¼šæä¾›çš„é¡¹ç›®è·¯å¾„ '{
                    args.project_path}' (è§£æä¸º '{project_root_abs}') ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ç›®å½•ã€‚")
            sys.exit(4)

        checker = StructureChecker(project_root_abs)  # ä½¿ç”¨è§£æåçš„ç»å¯¹è·¯å¾„

        if args.only_check_forbidden:
            # ä»…æ‰§è¡Œç¦æ­¢é¡¹æ£€æŸ¥
            print("ğŸ” ä»…æ‰§è¡Œç¦æ­¢é¡¹æ£€æŸ¥...")
            paths_to_check = []

            # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æ’é™¤ç›®å½•
            excluded_for_scan_entirely = set(
                CONFIG.get(
                    'structure_check',
                    {}).get(
                    'excluded_dirs',
                    [
                        '.git',
                        '.hg',
                        '.svn',
                        'node_modules',
                        '__pycache__',
                        '.pytest_cache',
                        '.mypy_cache',
                        'build',
                        'dist',
                        '*.egg-info']))
            print(f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶åŠ è½½æ’é™¤ç›®å½•: {', '.join(excluded_for_scan_entirely)}")

            for path_object in project_root_abs.rglob("*"):
                try:
                    # æ£€æŸ¥æ˜¯å¦åœ¨å®Œå…¨æ’é™¤æ‰«æçš„ç›®å½•ä¸­
                    if any(
                            part in excluded_for_scan_entirely for part in path_object.parts):
                        continue
                    paths_to_check.append(path_object)
                except ValueError:
                    continue  # å¿½ç•¥ä¸åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„è·¯å¾„

            checker.check_forbidden_items(paths_to_check)

            # ç”Ÿæˆç®€åŒ–æŠ¥å‘Š
            # è®¡ç®—å¾—åˆ† - ç¦æ­¢é¡¹æ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªç¦æ­¢é¡¹æ‰£20åˆ†ï¼Œæœ€ä½0åˆ†
            score = max(0, 100 - len(checker.issues) * 20)
            # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æ ‡å‡†æ¸…å•æ–‡ä»¶è·¯å¾„
            standard_list_file = CONFIG.get(
                'structure_check', {}).get(
                'standard_list_file', 'docs/01-è®¾è®¡/ç›®å½•ç»“æ„æ ‡å‡†æ¸…å•.md')
            standard_file_path = PROJECT_ROOT / standard_list_file

            report_data = {
                "check_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "project_root_checked": str(project_root_abs),
                "standard_file_used": str(standard_file_path),
                "overall_status": "âœ… æ£€æŸ¥é€šè¿‡" if not checker.issues else f"âŒ æ£€æŸ¥å¤±è´¥ - å‘ç°{len(checker.issues)}ä¸ªç¦æ­¢é¡¹",
                "final_score": score,  # æ·»åŠ å¾—åˆ†å­—æ®µ
                "summary_counts": {
                    "total_issues": len(checker.issues),
                    "total_warnings": 0,
                    "total_redundant_items": 0,
                    "total_missing_items": 0,
                    "total_info_logs": len(checker.info),
                    "total_items_scanned": len(paths_to_check)
                },
                "detailed_findings": {
                    "critical_issues": checker.issues,
                    "improvement_warnings": [],
                    "unnecessary_items": [],
                    "missing_required_items": [],
                    "informational_logs": checker.info,
                },
            }

            # æ‰“å°æŠ¥å‘Šåˆ°æ§åˆ¶å°
            checker.print_report_to_console(report_data)

            # æ ¹æ®æŠ¥å‘Šä¸­çš„ issues è¿”å›é€‚å½“çš„é€€å‡ºç 
            if len(checker.issues) > 0:
                sys.exit(1)  # æœ‰ç¦æ­¢é¡¹é—®é¢˜
            else:
                sys.exit(0)  # å®Œå…¨é€šè¿‡
        else:
            # æ‰§è¡Œå®Œæ•´æ£€æŸ¥
            report_data = checker.check_all()

            # æ‰“å°æŠ¥å‘Šåˆ°æ§åˆ¶å°
            checker.print_report_to_console(report_data)

            # æ ¹æ®æŠ¥å‘Šä¸­çš„ summary_counts è¿”å›é€‚å½“çš„é€€å‡ºç 
            summary_counts = report_data.get("summary_counts", {})
            if summary_counts.get(
                    "total_issues",
                    0) > 0 or summary_counts.get(
                    "total_redundant_items",
                    0) > 0:
                sys.exit(1)  # æœ‰ä¸¥é‡é—®é¢˜æˆ–å†—ä½™é¡¹
            elif summary_counts.get("total_warnings", 0) > 0:
                sys.exit(2)  # æœ‰è­¦å‘Š
            elif summary_counts.get("total_missing_items", 0) > 0:
                sys.exit(0)  # é€šè¿‡ä½†æœ‰ç¼ºå¤±é¡¹ï¼Œä¹Ÿç®—é€šè¿‡ï¼Œä½†æç¤ºç”¨æˆ·
            else:
                sys.exit(0)  # å®Œå…¨é€šè¿‡

    except IndexError:
        print("âŒ é”™è¯¯: è¯·æä¾›é¡¹ç›®æ ¹ç›®å½•ä½œä¸ºå‘½ä»¤è¡Œå‚æ•°ã€‚")
        print("ç”¨æ³•: python check_structure.py /path/to/your/project")
        sys.exit(4)  # å‚æ•°é”™è¯¯
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æ–™çš„é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(3)  # å…¶ä»–é”™è¯¯


if __name__ == "__main__":
    main()
