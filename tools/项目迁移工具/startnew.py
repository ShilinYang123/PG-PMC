#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
3AIé¡¹ç›®æ¨¡æ¿è¿ç§»å·¥å…·

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨æ£€æµ‹æ–°é¡¹ç›®æ ¹ç›®å½•
2. æ¸…ç†æ¨¡æ¿ä¸­çš„è¿è¡Œæ—¶æ•°æ®
3. æ›´æ–°é¡¹ç›®é…ç½®æ–‡ä»¶
4. é‡ç½®æ–‡æ¡£æ¨¡æ¿
5. åˆå§‹åŒ–æ–°é¡¹ç›®ç¯å¢ƒ

ä½¿ç”¨æ–¹æ³•ï¼š
    # åœ¨æ–°é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œï¼ˆè‡ªåŠ¨ä½¿ç”¨ç›®å½•åç§°ä½œä¸ºé¡¹ç›®åç§°ï¼‰
    python tools/é¡¹ç›®è¿ç§»å·¥å…·/startnew.py

    # è¯¦ç»†è¾“å‡º
    python tools/é¡¹ç›®è¿ç§»å·¥å…·/startnew.py --verbose

ä½œè€…ï¼šé›¨ä¿Š
ç‰ˆæœ¬ï¼š1.0
æ›´æ–°ï¼š2025-01-20
"""

# import os  # æœªä½¿ç”¨çš„å¯¼å…¥
import sys
import shutil
import argparse
import logging
import yaml
import json
import re
from pathlib import Path
from datetime import datetime
# from typing import Dict, List, Optional  # æœªä½¿ç”¨çš„å¯¼å…¥

# æ·»åŠ toolsç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

# å¯¼å…¥é¡¹ç›®å·¥å…·
try:
    from exceptions import ValidationError, ErrorHandler
    from utils import ensure_dir_exists
    from config_loader import ConfigLoader
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥é¡¹ç›®å·¥å…·æ¨¡å—ï¼Œä½¿ç”¨åŸºç¡€åŠŸèƒ½")

    class ValidationError(Exception):
        pass

    class ErrorHandler:
        def handle_error(self, error, context=""):
            logging.error(f"{context}: {error}")

    def ensure_dir_exists(path):
        Path(path).mkdir(parents=True, exist_ok=True)
        return True

    class ConfigLoader:
        def __init__(self, project_root):
            self.project_root = project_root
            self.config = self._load_config()

        def _load_config(self):
            """åŠ è½½é¡¹ç›®é…ç½®"""
            config_file = self.project_root / "docs" / "03-ç®¡ç†" / "project_config.yaml"
            if config_file.exists():
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        return yaml.safe_load(f)
                except Exception as e:
                    print(f"è­¦å‘Š: æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ {config_file}: {e}")
            return self._get_default_config()

        def _get_default_config(self):
            """è·å–é»˜è®¤é…ç½®"""
            return {
                'paths': {
                    'backup_dir': 'bak',
                    'docs_dir': 'docs',
                    'logs_dir': 'logs',
                    'tools_dir': 'tools',
                    'project_dir': 'project'
                }
            }

        def get_path(self, path_key):
            """è·å–é…ç½®åŒ–è·¯å¾„"""
            paths = self.config.get('paths', {})
            path_value = paths.get(path_key, path_key)
            # å¤„ç†è·¯å¾„ä¸­çš„æ¨¡æ¿å˜é‡
            if isinstance(path_value, str) and '{{' in path_value:
                path_value = path_value.replace(
                    '{{ PROJECT_ROOT }}', str(self.project_root))
                path_value = path_value.replace(
                    '{{PROJECT_ROOT}}', str(self.project_root))
            return path_value

        def _process_template_variables(self, content, project_name=None):
            if isinstance(content, str):
                content = content.replace(
                    '{{PROJECT_NAME}}', project_name or 'NewProject')
                content = content.replace(
                    '{{PROJECT_ROOT}}', str(
                        self.project_root))
                content = content.replace(
                    '{{PROJECT_DESCRIPTION}}', f'{project_name}é¡¹ç›®')
                content = content.replace(
                    '{{CREATED_AT}}', datetime.now().isoformat())
                content = content.replace(
                    '{{UPDATED_AT}}', datetime.now().isoformat())
            return content

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/å…¶ä»–æ—¥å¿—/é¡¹ç›®è¿ç§».log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)
error_handler = ErrorHandler()


class ProjectMigrator:
    """é¡¹ç›®è¿ç§»å¤„ç†å™¨"""

    def __init__(
            self,
            project_root: Path,
            project_name: str = None,
            verbose: bool = False):
        self.project_root = project_root
        self.project_name = project_name or project_root.name
        self.verbose = verbose

        # åˆå§‹åŒ–é…ç½®åŠ è½½å™¨
        self.config_loader = ConfigLoader(project_root)

        # ä½¿ç”¨é…ç½®åŒ–è·¯å¾„
        backup_dir = self.config_loader.get_path('backup_dir')
        self.backup_dir = project_root / backup_dir / "è¿ç§»å¤‡ä»½"

        logs_dir = self.config_loader.get_path('logs_dir')
        self.logs_dir = project_root / logs_dir

        docs_dir = self.config_loader.get_path('docs_dir')
        self.docs_dir = project_root / docs_dir

        tools_dir = self.config_loader.get_path('tools_dir')
        self.tools_dir = project_root / tools_dir

        project_dir = self.config_loader.get_path('project_dir')
        self.project_dir = project_root / project_dir

        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        ensure_dir_exists(self.logs_dir)

        logger.info(f"åˆå§‹åŒ–é¡¹ç›®è¿ç§»å™¨: {self.project_root}")
        logger.info(f"é¡¹ç›®åç§°: {self.project_name}")
        logger.info(f"ä½¿ç”¨é…ç½®åŒ–è·¯å¾„: backup_dir={backup_dir}, logs_dir={logs_dir}")

    def run_migration(self) -> bool:
        """æ‰§è¡Œå®Œæ•´çš„é¡¹ç›®è¿ç§»æµç¨‹"""
        try:
            logger.info("=" * 60)
            logger.info("å¼€å§‹é¡¹ç›®è¿ç§»æµç¨‹")
            logger.info("=" * 60)

            # 1. éªŒè¯é¡¹ç›®ç»“æ„
            if not self._validate_project_structure():
                return False

            # 2. åˆ›å»ºå¤‡ä»½
            self._create_backup()

            # 3. æ¸…ç†è¿è¡Œæ—¶æ•°æ®
            self._clean_runtime_data()

            # 4. æ›´æ–°é…ç½®æ–‡ä»¶
            self._update_configurations()

            # 5. é‡ç½®æ–‡æ¡£æ¨¡æ¿
            self._reset_document_templates()

            # 6. æ›´æ–°å·¥å…·è„šæœ¬
            self._update_tool_scripts()

            # 7. å¤„ç†æµ‹è¯•æ–‡ä»¶
            self._update_test_files()

            # 8. æ¸…ç†ç¼“å­˜æ–‡ä»¶
            self._clean_cache_files()

            # 9. éªŒè¯è¿ç§»ç»“æœ
            self._validate_migration()

            # 10. ç”Ÿæˆè¿ç§»æŠ¥å‘Š
            self._generate_migration_report()

            logger.info("=" * 60)
            logger.info("é¡¹ç›®è¿ç§»å®Œæˆï¼")
            logger.info(f"æ–°é¡¹ç›®åç§°: {self.project_name}")
            logger.info(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
            logger.info("=" * 60)

            return True

        except Exception as e:
            error_handler.handle_error(e, "é¡¹ç›®è¿ç§»å¤±è´¥")
            return False

    def _validate_project_structure(self) -> bool:
        """éªŒè¯é¡¹ç›®ç»“æ„å®Œæ•´æ€§"""
        logger.info("éªŒè¯é¡¹ç›®ç»“æ„...")

        required_dirs = ['bak', 'docs', 'logs', 'project', 'tools']
        missing_dirs = []

        for dir_name in required_dirs:
            dir_path = self.project_root / dir_name
            if not dir_path.exists():
                missing_dirs.append(dir_name)

        if missing_dirs:
            logger.error(f"ç¼ºå°‘å¿…éœ€ç›®å½•: {missing_dirs}")
            return False

        logger.info("é¡¹ç›®ç»“æ„éªŒè¯é€šè¿‡")
        return True

    def _create_backup(self):
        """åˆ›å»ºè¿ç§»å‰å¤‡ä»½"""
        logger.info("åˆ›å»ºè¿ç§»å¤‡ä»½...")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"è¿ç§»å‰å¤‡ä»½_{timestamp}"
        backup_path = self.backup_dir / backup_name

        ensure_dir_exists(backup_path)

        # å¤‡ä»½å…³é”®é…ç½®æ–‡ä»¶ï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        config_files = [
            self.docs_dir / "03-ç®¡ç†" / "project_config.yaml",
            self.docs_dir / "03-ç®¡ç†" / ".env",
            self.docs_dir / "02-å¼€å‘" / "memory.json",
            self.docs_dir / "02-å¼€å‘" / "tasks.json"
        ]

        for config_file in config_files:
            if config_file.exists():
                # è®¡ç®—ç›¸å¯¹è·¯å¾„ç”¨äºå¤‡ä»½ç›®å½•ç»“æ„
                rel_path = config_file.relative_to(self.project_root)
                target = backup_path / rel_path
                ensure_dir_exists(target.parent)
                shutil.copy2(config_file, target)
                logger.info(f"å¤‡ä»½: {rel_path}")

    def _clean_runtime_data(self):
        """æ¸…ç†è¿è¡Œæ—¶æ•°æ®"""
        logger.info("æ¸…ç†è¿è¡Œæ—¶æ•°æ®...")

        # æ¸…ç†æ—¥å¿—æ–‡ä»¶ï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        if self.logs_dir.exists():
            for log_file in self.logs_dir.glob("*.log"):
                log_file.unlink()
                logger.info(f"åˆ é™¤æ—¥å¿—: {log_file.name}")

            for json_file in self.logs_dir.glob("*.json"):
                json_file.unlink()
                logger.info(f"åˆ é™¤æ—¥å¿—: {json_file.name}")

            for txt_file in self.logs_dir.glob("*.txt"):
                txt_file.unlink()
                logger.info(f"åˆ é™¤æ—¥å¿—: {txt_file.name}")

        # æ¸…ç†å¼€å‘æ•°æ®ï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        dev_files = [
            self.docs_dir / "02-å¼€å‘" / "memory.json",
            self.docs_dir / "02-å¼€å‘" / "tasks.json"
        ]

        for dev_file in dev_files:
            if dev_file.exists():
                rel_path = dev_file.relative_to(self.project_root)
                dev_file.unlink()
                logger.info(f"åˆ é™¤å¼€å‘æ•°æ®: {rel_path}")

        # æ¸…ç†å†å²å¤‡ä»½ï¼ˆä¿ç•™å¤‡ä»½ç›®å½•ç»“æ„ï¼Œä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        bak_dirs = ['ä¸“é¡¹å¤‡ä»½', 'æ—¥å¸¸å¤‡ä»½', 'å¾…æ¸…ç†èµ„æ–™']
        for bak_dir in bak_dirs:
            bak_path = self.backup_dir / bak_dir
            if bak_path.exists():
                for item in bak_path.iterdir():
                    if item.is_file():
                        item.unlink()
                        logger.info(f"æ¸…ç†å¤‡ä»½æ–‡ä»¶: {item.name}")

    def _update_configurations(self):
        """æ›´æ–°é…ç½®æ–‡ä»¶"""
        logger.info("æ›´æ–°é¡¹ç›®é…ç½®...")

        # åˆå§‹åŒ–é…ç½®åŠ è½½å™¨
        try:
            config_loader = ConfigLoader(self.project_root)
        except BaseException:
            config_loader = None

        # æ›´æ–°project_config.yamlï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        config_file = self.docs_dir / "03-ç®¡ç†" / "project_config.yaml"
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # å¤„ç†æ¨¡æ¿å˜é‡
            if config_loader:
                content = config_loader._process_template_variables(
                    content, self.project_name)
            else:
                content = content.replace(
                    '{{PROJECT_NAME}}', self.project_name)
                content = content.replace(
                    '{{PROJECT_ROOT}}', str(
                        self.project_root))
                content = content.replace(
                    '{{PROJECT_DESCRIPTION}}', f'{
                        self.project_name}é¡¹ç›®')
                content = content.replace(
                    '{{CREATED_AT}}', datetime.now().isoformat())
                content = content.replace(
                    '{{UPDATED_AT}}', datetime.now().isoformat())

            # è§£æå¹¶æ›´æ–°é…ç½®
            config = yaml.safe_load(content)

            # ç¡®ä¿é¡¹ç›®ä¿¡æ¯æ­£ç¡®
            if 'project' not in config:
                config['project'] = {}
            config['project']['name'] = self.project_name
            config['project']['root'] = str(self.project_root)
            config['project']['created_at'] = datetime.now().isoformat()
            config['project']['updated_at'] = datetime.now().isoformat()

            # æ›´æ–°æ•°æ®åº“é…ç½®
            if 'database' in config:
                if 'name' in config['database']:
                    config['database']['name'] = f"{
                        self.project_name.lower().replace(
                            '-', '_')}_db"

            # æ›´æ–°åº”ç”¨é…ç½®
            if 'app' in config:
                if 'name' in config['app']:
                    config['app']['name'] = self.project_name

            with open(config_file, 'w', encoding='utf-8') as f:
                yaml.dump(
                    config,
                    f,
                    default_flow_style=False,
                    allow_unicode=True)

            logger.info("æ›´æ–°project_config.yamlå®Œæˆ")

        # æ›´æ–°package.jsonï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        package_file = self.project_root / "package.json"
        if package_file.exists():
            with open(package_file, 'r', encoding='utf-8') as f:
                package_config = json.load(f)

            package_config['name'] = self.project_name.lower().replace(
                ' ', '-')
            package_config['description'] = f'{self.project_name}é¡¹ç›®'

            with open(package_file, 'w', encoding='utf-8') as f:
                json.dump(package_config, f, indent=2, ensure_ascii=False)

            logger.info("æ›´æ–°package.jsonå®Œæˆ")

        # é‡ç½®.envæ–‡ä»¶ï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        env_file = self.docs_dir / "03-ç®¡ç†" / ".env"
        if env_file.exists():
            env_example = self.docs_dir / "03-ç®¡ç†" / ".env.example"
            if env_example.exists():
                shutil.copy2(env_example, env_file)

                # æ›´æ–°.envæ–‡ä»¶ä¸­çš„é¡¹ç›®åç§°
                content = env_file.read_text(encoding='utf-8')
                content = content.replace(
                    '{{PROJECT_NAME}}', self.project_name)
                content = content.replace(
                    '{{PROJECT_ROOT}}', str(
                        self.project_root))
                env_file.write_text(content, encoding='utf-8')

                logger.info("é‡ç½®å¹¶æ›´æ–°.envæ–‡ä»¶")

        # æ›´æ–°Dockeré…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        self._update_docker_configs()

        # æ›´æ–°å…¶ä»–é…ç½®æ–‡ä»¶
        self._update_other_configs()

    def _update_docker_configs(self):
        """æ›´æ–°Dockeré…ç½®æ–‡ä»¶"""
        logger.info("æ›´æ–°Dockeré…ç½®...")

        # æ›´æ–°docker-compose.yml
        compose_file = self.project_root / "docker-compose.yml"
        if compose_file.exists():
            content = compose_file.read_text(encoding='utf-8')
            content = content.replace(
                '{{PROJECT_NAME}}',
                self.project_name.lower().replace(
                    ' ',
                    '-'))
            content = content.replace(
                '{{PROJECT_ROOT}}', str(
                    self.project_root))
            compose_file.write_text(content, encoding='utf-8')
            logger.info("æ›´æ–°docker-compose.yml")

        # æ›´æ–°Dockerfile
        dockerfile = self.project_root / "Dockerfile"
        if dockerfile.exists():
            content = dockerfile.read_text(encoding='utf-8')
            content = content.replace('{{PROJECT_NAME}}', self.project_name)
            dockerfile.write_text(content, encoding='utf-8')
            logger.info("æ›´æ–°Dockerfile")

    def _update_other_configs(self):
        """æ›´æ–°å…¶ä»–é…ç½®æ–‡ä»¶"""
        logger.info("æ›´æ–°å…¶ä»–é…ç½®æ–‡ä»¶...")

        # æ›´æ–°README.md
        readme_files = [
            self.project_root / "README.md",
            self.project_root / "project" / "README.md"
        ]

        for readme_file in readme_files:
            if readme_file.exists():
                content = readme_file.read_text(encoding='utf-8')
                content = content.replace(
                    '{{PROJECT_NAME}}', self.project_name)
                content = content.replace(
                    '{{PROJECT_ROOT}}', str(
                        self.project_root))
                content = content.replace(
                    '{{PROJECT_DESCRIPTION}}', f'{
                        self.project_name}é¡¹ç›®')
                readme_file.write_text(content, encoding='utf-8')
                logger.info(f"æ›´æ–°{readme_file.name}")

    def _reset_document_templates(self):
        """é‡ç½®æ–‡æ¡£æ¨¡æ¿"""
        logger.info("é‡ç½®æ–‡æ¡£æ¨¡æ¿...")

        # å¤„ç†æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶ï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        doc_files = [
            self.docs_dir / "01-è®¾è®¡" / "å¼€å‘ä»»åŠ¡ä¹¦.md",
            self.docs_dir / "01-è®¾è®¡" / "æŠ€æœ¯è·¯çº¿.md",
            self.docs_dir / "01-è®¾è®¡" / "é¡¹ç›®æ¶æ„è®¾è®¡.md",
            self.docs_dir / "01-è®¾è®¡" / "ç›®å½•ç»“æ„æ ‡å‡†æ¸…å•.md",
            self.docs_dir / "03-ç®¡ç†" / "è§„èŒƒä¸æµç¨‹.md",
            self.docs_dir / "03-ç®¡ç†" / "é¡¹ç›®æ¨¡æ¿åŒ–æ ‡å‡†.md"
        ]

        for doc_file in doc_files:
            if doc_file.exists():
                content = doc_file.read_text(encoding='utf-8')

                # æ›¿æ¢æ¨¡æ¿å˜é‡
                content = content.replace(
                    '{{PROJECT_NAME}}', self.project_name)
                content = content.replace(
                    '{{PROJECT_ROOT}}', str(
                        self.project_root))
                content = content.replace(
                    '{{PROJECT_DESCRIPTION}}', f'{
                        self.project_name}é¡¹ç›®')
                content = content.replace(
                    '{{CREATED_AT}}', datetime.now().isoformat())
                content = content.replace(
                    '{{UPDATED_AT}}', datetime.now().isoformat())

                # ç‰¹æ®Šå¤„ç†ï¼šæ›´æ–°æ ‡é¢˜
                if "å¼€å‘ä»»åŠ¡ä¹¦" in doc_file:
                    content = re.sub(
                        r'é¡¹ç›®åç§°ï¼š.*',
                        f'é¡¹ç›®åç§°ï¼š{
                            self.project_name}',
                        content)
                    content = re.sub(
                        r'# .*é¡¹ç›®å¼€å‘ä»»åŠ¡ä¹¦',
                        f'# {
                            self.project_name}é¡¹ç›®å¼€å‘ä»»åŠ¡ä¹¦',
                        content)
                elif "æŠ€æœ¯è·¯çº¿" in doc_file:
                    content = re.sub(
                        r'# .*æŠ€æœ¯è·¯çº¿',
                        f'# {
                            self.project_name}æŠ€æœ¯è·¯çº¿',
                        content)
                elif "é¡¹ç›®æ¶æ„è®¾è®¡" in doc_file:
                    content = re.sub(
                        r'# .*é¡¹ç›®æ¶æ„è®¾è®¡',
                        f'# {
                            self.project_name}é¡¹ç›®æ¶æ„è®¾è®¡',
                        content)

                doc_file.write_text(content, encoding='utf-8')
                rel_path = doc_file.relative_to(self.project_root)
                logger.info(f"æ›´æ–°{rel_path}")

    def _clean_cache_files(self):
        """æ¸…ç†ç¼“å­˜æ–‡ä»¶"""
        logger.info("æ¸…ç†ç¼“å­˜æ–‡ä»¶...")

        # æ¸…ç†Pythonç¼“å­˜
        pycache_dirs = list(self.project_root.rglob("__pycache__"))
        for pycache_dir in pycache_dirs:
            shutil.rmtree(pycache_dir)
            logger.info(f"åˆ é™¤ç¼“å­˜ç›®å½•: {pycache_dir}")

        # æ¸…ç†.pycæ–‡ä»¶
        pyc_files = list(self.project_root.rglob("*.pyc"))
        for pyc_file in pyc_files:
            pyc_file.unlink()
            logger.info(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶: {pyc_file}")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        temp_patterns = ['*.tmp', '*.temp', '*.bak', '*.swp', '*~']
        for pattern in temp_patterns:
            temp_files = list(self.project_root.rglob(pattern))
            for temp_file in temp_files:
                temp_file.unlink()
                logger.info(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file}")

    def _update_tool_scripts(self):
        """æ›´æ–°å·¥å…·è„šæœ¬"""
        logger.info("æ›´æ–°å·¥å…·è„šæœ¬...")

        # æ›´æ–°å·¥å…·ç›®å½•ä¸‹çš„Pythonè„šæœ¬ï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        tools_dir = self.tools_dir
        if tools_dir.exists():
            for py_file in tools_dir.rglob("*.py"):
                if py_file.name == "startnew.py":  # è·³è¿‡å½“å‰è„šæœ¬
                    continue

                try:
                    content = py_file.read_text(encoding='utf-8')
                    original_content = content

                    # æ›¿æ¢æ¨¡æ¿å˜é‡
                    content = content.replace(
                        '{{PROJECT_NAME}}', self.project_name)
                    content = content.replace(
                        '{{PROJECT_ROOT}}', str(
                            self.project_root))
                    content = content.replace(
                        '{{PROJECT_DESCRIPTION}}', f'{
                            self.project_name}é¡¹ç›®')

                    # æ›´æ–°ç¡¬ç¼–ç çš„é¡¹ç›®åç§°å¼•ç”¨
                    content = re.sub(
                        r'3AI(?!é¡¹ç›®è¿ç§»å·¥å…·)', self.project_name, content)
                    content = re.sub(
                        r'3ai(?!é¡¹ç›®è¿ç§»å·¥å…·)', self.project_name.lower(), content)

                    if content != original_content:
                        py_file.write_text(content, encoding='utf-8')
                        logger.info(
                            f"æ›´æ–°å·¥å…·è„šæœ¬: {
                                py_file.relative_to(
                                    self.project_root)}")

                except Exception as e:
                    logger.warning(f"æ›´æ–°å·¥å…·è„šæœ¬å¤±è´¥ {py_file}: {e}")

    def _update_test_files(self):
        """æ›´æ–°æµ‹è¯•æ–‡ä»¶"""
        logger.info("æ›´æ–°æµ‹è¯•æ–‡ä»¶...")

        # æ›´æ–°æµ‹è¯•ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        test_dirs = [
            self.tools_dir / "tests",
            self.project_dir / "tests",
            self.project_root / "tests"
        ]

        for test_dir in test_dirs:
            if test_dir.exists():
                for test_file in test_dir.rglob("*.py"):
                    try:
                        content = test_file.read_text(encoding='utf-8')
                        original_content = content

                        # æ›¿æ¢æ¨¡æ¿å˜é‡
                        content = content.replace(
                            '{{PROJECT_NAME}}', self.project_name)
                        content = content.replace(
                            '{{PROJECT_ROOT}}', str(self.project_root))

                        # æ›´æ–°æµ‹è¯•è·¯å¾„ - æ›¿æ¢æ—§çš„ç¡¬ç¼–ç è·¯å¾„ä¸ºæ–°çš„é¡¹ç›®æ ¹ç›®å½•
                        # å¤„ç†å¯èƒ½çš„æ—§è·¯å¾„æ ¼å¼
                        old_path_patterns = [
                            r's:\\3AI',
                            r'S:\\3AI',
                            r's:/3AI',
                            r'S:/3AI'
                        ]

                        new_project_root = str(
                            self.project_root).replace(
                            '\\', '\\\\')
                        for pattern in old_path_patterns:
                            content = re.sub(
                                pattern, new_project_root, content, flags=re.IGNORECASE)

                        if content != original_content:
                            test_file.write_text(content, encoding='utf-8')
                            logger.info(
                                f"æ›´æ–°æµ‹è¯•æ–‡ä»¶: {
                                    test_file.relative_to(
                                        self.project_root)}")

                    except Exception as e:
                        logger.warning(f"æ›´æ–°æµ‹è¯•æ–‡ä»¶å¤±è´¥ {test_file}: {e}")

    def _validate_migration(self):
        """éªŒè¯è¿ç§»ç»“æœ"""
        logger.info("éªŒè¯è¿ç§»ç»“æœ...")

        validation_errors = []

        # éªŒè¯é…ç½®æ–‡ä»¶ï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        config_file = self.docs_dir / "03-ç®¡ç†" / "project_config.yaml"
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªæ›¿æ¢çš„æ¨¡æ¿å˜é‡
                config_str = yaml.dump(config)
                if '{{' in config_str and '}}' in config_str:
                    validation_errors.append("é…ç½®æ–‡ä»¶ä¸­ä»æœ‰æœªæ›¿æ¢çš„æ¨¡æ¿å˜é‡")

                # æ£€æŸ¥é¡¹ç›®åç§°æ˜¯å¦æ­£ç¡®è®¾ç½®
                if config.get('project', {}).get('name') != self.project_name:
                    validation_errors.append("é¡¹ç›®åç§°æœªæ­£ç¡®è®¾ç½®")

            except Exception as e:
                validation_errors.append(f"é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")

        # éªŒè¯å…³é”®ç›®å½•å­˜åœ¨ï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        required_dirs = {
            'docs': self.docs_dir,
            'tools': self.tools_dir,
            'logs': self.logs_dir,
            'bak': self.backup_dir
        }
        for dir_name, dir_path in required_dirs.items():
            if not dir_path.exists():
                validation_errors.append(f"ç¼ºå°‘å¿…éœ€ç›®å½•: {dir_name}")

        # éªŒè¯å·¥å…·è„šæœ¬ï¼ˆä½¿ç”¨é…ç½®åŒ–è·¯å¾„ï¼‰
        key_tools = [
            self.tools_dir / "config_loader.py",
            self.tools_dir / "é¡¹ç›®è¿ç§»å·¥å…·" / "startnew.py"
        ]
        for tool in key_tools:
            if not tool.exists():
                try:
                    rel_path = tool.relative_to(self.project_root)
                    validation_errors.append(f"ç¼ºå°‘å…³é”®å·¥å…·: {rel_path}")
                except ValueError:
                    validation_errors.append(f"ç¼ºå°‘å…³é”®å·¥å…·: {tool}")

        if validation_errors:
            logger.warning("è¿ç§»éªŒè¯å‘ç°é—®é¢˜:")
            for error in validation_errors:
                logger.warning(f"  - {error}")
        else:
            logger.info("è¿ç§»éªŒè¯é€šè¿‡")

    def _generate_migration_report(self):
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        logger.info("ç”Ÿæˆè¿ç§»æŠ¥å‘Š...")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # ä»é…ç½®æ–‡ä»¶è·å–æŠ¥å‘Šç›®å½•
        report_dir = self.config_loader.config.get(
            'structure_check', {}).get('report_dir', 'logs/æ£€æŸ¥æŠ¥å‘Š')
        report_dir_name = report_dir.split('/')[-1]  # è·å–æœ€åä¸€çº§ç›®å½•å
        report_file = self.logs_dir / report_dir_name / f"é¡¹ç›®è¿ç§»æŠ¥å‘Š_{timestamp}.md"

        report_content = f"""# {self.project_name}é¡¹ç›®è¿ç§»æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯

- **é¡¹ç›®åç§°**: {self.project_name}
- **é¡¹ç›®æ ¹ç›®å½•**: {self.project_root}
- **è¿ç§»æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **è¿ç§»å·¥å…·ç‰ˆæœ¬**: 1.0

## è¿ç§»æ­¥éª¤

âœ… é¡¹ç›®ç»“æ„éªŒè¯
âœ… åˆ›å»ºè¿ç§»å¤‡ä»½
âœ… æ¸…ç†è¿è¡Œæ—¶æ•°æ®
âœ… æ›´æ–°é…ç½®æ–‡ä»¶
âœ… é‡ç½®æ–‡æ¡£æ¨¡æ¿
âœ… æ›´æ–°å·¥å…·è„šæœ¬
âœ… å¤„ç†æµ‹è¯•æ–‡ä»¶
âœ… æ¸…ç†ç¼“å­˜æ–‡ä»¶
âœ… éªŒè¯è¿ç§»ç»“æœ
âœ… ç”Ÿæˆè¿ç§»æŠ¥å‘Š

## æ¸…ç†å†…å®¹

### è¿è¡Œæ—¶æ•°æ®
- åˆ é™¤logsç›®å½•ä¸‹çš„æ‰€æœ‰æ—¥å¿—æ–‡ä»¶
- åˆ é™¤docs/02-å¼€å‘/memory.json
- åˆ é™¤docs/02-å¼€å‘/tasks.json
- æ¸…ç†bakç›®å½•ä¸‹çš„å†å²å¤‡ä»½æ–‡ä»¶

### ç¼“å­˜æ–‡ä»¶
- åˆ é™¤æ‰€æœ‰__pycache__ç›®å½•
- åˆ é™¤æ‰€æœ‰.pycæ–‡ä»¶

### é…ç½®æ›´æ–°
- æ›´æ–°project_config.yamlä¸­çš„é¡¹ç›®ä¿¡æ¯å’Œæ¨¡æ¿å˜é‡
- æ›´æ–°package.jsonä¸­çš„é¡¹ç›®åç§°å’Œæè¿°
- é‡ç½®å¹¶æ›´æ–°.envæ–‡ä»¶
- æ›´æ–°Dockeré…ç½®æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
- æ›´æ–°README.mdæ–‡ä»¶

### æ–‡æ¡£æ›´æ–°
- æ›´æ–°æ‰€æœ‰è®¾è®¡æ–‡æ¡£ä¸­çš„é¡¹ç›®åç§°å’Œæ¨¡æ¿å˜é‡
- æ›´æ–°ç®¡ç†æ–‡æ¡£ä¸­çš„é¡¹ç›®ä¿¡æ¯
- å¤„ç†æ–‡æ¡£ä¸­çš„è·¯å¾„å¼•ç”¨

### å·¥å…·å’Œæµ‹è¯•æ›´æ–°
- æ›´æ–°æ‰€æœ‰å·¥å…·è„šæœ¬ä¸­çš„é¡¹ç›®å¼•ç”¨
- æ›´æ–°æµ‹è¯•æ–‡ä»¶ä¸­çš„è·¯å¾„å’Œé¡¹ç›®åç§°
- æ›¿æ¢ç¡¬ç¼–ç çš„é¡¹ç›®åç§°å¼•ç”¨

## ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®

1. æ£€æŸ¥å¹¶å®Œå–„å¼€å‘ä»»åŠ¡ä¹¦
2. åˆ¶å®šå…·ä½“çš„æŠ€æœ¯è·¯çº¿
3. é…ç½®é¡¹ç›®ç‰¹å®šçš„ç¯å¢ƒå˜é‡
4. å¼€å§‹é¡¹ç›®å¼€å‘å·¥ä½œ

## å¤‡ä»½ä½ç½®

è¿ç§»å‰çš„é‡è¦é…ç½®æ–‡ä»¶å·²å¤‡ä»½åˆ°: `{Path(self.backup_dir).relative_to(self.project_root) / 'è¿ç§»å¤‡ä»½'}/`

---

*æ­¤æŠ¥å‘Šç”±{{PROJECT_NAME}}é¡¹ç›®è¿ç§»å·¥å…·è‡ªåŠ¨ç”Ÿæˆ*
"""

        report_file.write_text(report_content, encoding='utf-8')
        logger.info(f"è¿ç§»æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="3AIé¡¹ç›®æ¨¡æ¿è¿ç§»å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python startnew.py                           # è‡ªåŠ¨ä½¿ç”¨æ ¹ç›®å½•åç§°ä½œä¸ºé¡¹ç›®åç§°
  python startnew.py --verbose                 # è¯¦ç»†è¾“å‡º
        """
    )

    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º'
    )

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = Path.cwd()

    # éªŒè¯æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•ä¸­è¿è¡Œ
    script_path = project_root / "tools" / "é¡¹ç›®è¿ç§»å·¥å…·" / "startnew.py"
    if not script_path.exists():
        print("é”™è¯¯: è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
        print(f"æ­£ç¡®çš„è¿è¡Œæ–¹å¼: python {script_path.relative_to(project_root)}")
        sys.exit(1)

    # è‡ªåŠ¨ä½¿ç”¨æ ¹ç›®å½•åç§°ä½œä¸ºé¡¹ç›®åç§°
    project_name = project_root.name
    print(f"è‡ªåŠ¨æ£€æµ‹åˆ°é¡¹ç›®åç§°: {project_name}")

    # åˆ›å»ºè¿ç§»å™¨å¹¶æ‰§è¡Œè¿ç§»
    migrator = ProjectMigrator(
        project_root=project_root,
        project_name=project_name,
        verbose=args.verbose
    )

    success = migrator.run_migration()

    if success:
        print("\nğŸ‰ é¡¹ç›®è¿ç§»æˆåŠŸå®Œæˆï¼")
        print(f"æ–°é¡¹ç›®å·²å‡†å¤‡å°±ç»ª: {migrator.project_name}")
        print("\nå»ºè®®ä¸‹ä¸€æ­¥æ“ä½œ:")
        docs_design = Path(migrator.docs_dir) / "01-è®¾è®¡"
        docs_management = Path(migrator.docs_dir) / "03-ç®¡ç†"
        print(f"1. æ£€æŸ¥å¹¶å®Œå–„ {docs_design.relative_to(project_root) / 'å¼€å‘ä»»åŠ¡ä¹¦.md'}")
        print(f"2. åˆ¶å®šå…·ä½“çš„ {docs_design.relative_to(project_root) / 'æŠ€æœ¯è·¯çº¿.md'}")
        print(
            f"3. é…ç½® {
                docs_management.relative_to(project_root)
                / '.env'} ç¯å¢ƒå˜é‡")
        print("4. å¼€å§‹é¡¹ç›®å¼€å‘å·¥ä½œ")
        sys.exit(0)
    else:
        print("\nâŒ é¡¹ç›®è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶")
        sys.exit(1)


if __name__ == "__main__":
    main()
